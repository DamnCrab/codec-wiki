"use strict";(self.webpackChunkcodec_wiki=self.webpackChunkcodec_wiki||[]).push([[5894],{6042:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"svt-av1-deep-dive","metadata":{"permalink":"/blog/svt-av1-deep-dive","source":"@site/blog/2023-12-30-svt-av1-deep-dive.mdx","title":"Encoding Animation with SVT-AV1: A Deep Dive","description":"With the recent release of SVT-AV1 1.8.0, how does it stack up for encoding animation?","date":"2023-12-30T00:00:00.000Z","formattedDate":"December 30, 2023","tags":[{"label":"video","permalink":"/blog/tags/video"},{"label":"compression","permalink":"/blog/tags/compression"},{"label":"benchmarks","permalink":"/blog/tags/benchmarks"}],"readingTime":15.02,"hasTruncateMarker":true,"authors":[{"name":"Trix","title":"Encoder","url":"https://github.com/trixoniisama/","image_url":"https://avatars.githubusercontent.com/u/93526043","imageURL":"https://avatars.githubusercontent.com/u/93526043"}],"frontMatter":{"title":"Encoding Animation with SVT-AV1: A Deep Dive","description":"With the recent release of SVT-AV1 1.8.0, how does it stack up for encoding animation?","slug":"svt-av1-deep-dive","authors":[{"name":"Trix","title":"Encoder","url":"https://github.com/trixoniisama/","image_url":"https://avatars.githubusercontent.com/u/93526043","imageURL":"https://avatars.githubusercontent.com/u/93526043"}],"tags":["video","compression","benchmarks"],"image":"/img/svt-1.8.0-testing-blog-image.webp","hide_table_of_contents":false},"unlisted":false,"nextItem":{"title":"Embedding the Un-Embeddable","permalink":"/blog/embedding-the-un-embeddable"}},"content":"This blog post is based on a series of visual quality benchmarks with SSIMULACRA2 and speed benchmarks of SVT-AV1 1.8.0 on a corpus of animated clips.\\r\\n\\r\\nThe resources available will range from ***graphs*** to ~~**image comparisons**~~ (WIP). The ***former*** has the advantage of being easily understandable, showcasing pure efficiency comparisons between encoder parameters using metrics as the reference, while the **latter** are image samples from the encoded files during the tests that enable you to check quality for yourself and add another layer of subjective interpretation to these comparisons.\\r\\n\\r\\n\x3c!--truncate--\x3e\\r\\n\\r\\nThe testing methodology involves using relatively short video samples from a wide range of modern anime genre, which have been either losslessly encoded with `x264 --qp 0` for ease of use or losslessly cut from their source. These lossless files are then pipped into SvtAv1EncApp *directly*, meaning we are measuring the performance of a single encoder instance and not leveraging chunked encoding like any actual final AV1 encoding pipeline should. Once an encode is done, SSIMULACRA2 scores are calculated using the [Zig implementation](https://github.com/dnjulek/vapoursynth-ssimulacra2) and lots of useful data are aggregated to make the graphs for this benchmark, including encoding time, encode size (bitrate), and SSIMULACRA2 scores. Bits per pixel scores (BPP) are calculated so that the `Metric / BPP` graphs may represent the closest we have to real efficiency.\\r\\n\\r\\nThe clips used in this test were acquired legally. The Codec Wiki and its contributors do not endorse media piracy.\\r\\n\\r\\nSvtAv1EncApp was compiled directly from the [v1.8.0 source code](https://gitlab.com/AOMediaCodec/SVT-AV1/-/releases/v1.8.0) using the provided `Build/linux/build.sh` script, Clang 16.0.6, and Profile-Guided Optimization (PGO). The testing machine is comprised of an i7 8750H running at 35W with 16GB of 2666MHz DDR4 RAM in Arch Linux with kernel 6.6.6 and the performance governor enabled. All encodes have been made in the same session without rebooting.\\r\\n\\r\\nThis testing was conducted within the [AV1 Weeb Edition](https://discord.gg/83dRFDFDp7) Discord server, which is focused on encoding animated content in AV1.\\r\\n\\r\\n## Samples\\r\\n\\r\\nThe samples are as follows:\\r\\n- 11s `Blame!` clip which sports 3DCG action with lots of grain, effects and high-contrast elements. Most complex source of this set.\\r\\n- 13s `Blue Lock` clip which sports rapid camera movements and rotations + high-contrast elements.\\r\\n- 15s `Fate/Grand Order: Babylonia` relatively slow-paced clip with lots of effects still. Easiest source of this set but easy sources still give interesting data.\\r\\n- 22s `Jigokuraku (Hell\'s Paradise)` flashback clip with huge static grain in a very dark scenery and some action.\\r\\n- 14s `Kaguya-sama` opening sequence with lots of effects and fast change of scenery.\\r\\nThe resolution of every clip is 1080p, except for the first one which is 1920x804.\\r\\n\\r\\n> **All clips have been encoded in a wide quality range, from `--crf 8` to `--crf 43`.**\\r\\n\\r\\nWithout further ado, let\'s start with the first comparisons!\\r\\n\\r\\n## Presets comparisons (-1 -> 13)\\r\\n\\r\\n**In the following graphs, you may find comparisons between all SVT-AV1 presets, ranging from the slowest `--preset -1` to the fastest `--preset 13`.**\\r\\n*Please remember that these two extreme presets are meant for development purposes and as such should not be used in normal encoding conditions. You will soon understand why.*\\r\\n\\r\\n`--preset X` is the only parameter used here, in conjunction with the CRF values. That means everything else is default. The defaults worth mentioning are: \\r\\n- `--tune 1`: tune PSNR\\r\\n- `--aq-mode 2`: variance deltaq\\r\\n- `--enable-qm 0`: quantisation matrices disabled\\r\\n- `--irefresh-type 2`: closed GOP\\r\\n- `--enable-tf 1`: temporal filtering enabled\\r\\nAnd more, like CDEF and restoration enabled, overlays and film-grain disabled...\\r\\n\\r\\n- First of all, here are the efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-graphs/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-graphs/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-graphs/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-graphs/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-graphs/SVT4_kaguya.webp)\\r\\n\\r\\nThis could be too much information.\\r\\n\\r\\n- Now the same graphs but focusing on the \\"high quality\\" range (CRF8 -> 23):\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-highq/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-highq/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-highq/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-highq/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-highq/SVT4_kaguya.webp)\\r\\n\\r\\n- Same again but without presets 9 to 13 for better clarity:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-highq-slow/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-highq-slow/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-highq-slow/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-highq-slow/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-highq-slow/SVT4_kaguya.webp)\\r\\n\\r\\n- Now for the \\"low quality\\" range (CRF28 -> 43):\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-lowq/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-lowq/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-lowq/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-lowq/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-lowq/SVT4_kaguya.webp)\\r\\n\\r\\n- Same but without presets 9 to 13 for better clarity:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-lowq-slow/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-lowq-slow/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-lowq-slow/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-lowq-slow/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/svt-efficiency-lowq-slow/SVT4_kaguya.webp)\\r\\n\\r\\n- **Let\'s now see speed comparisons between all presets:**\\r\\n\\r\\n![speed_overall](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed_overall.webp)\\r\\n\\r\\nAs we can see, preset -1 is so abysmally slow it makes the graph unusable\\r\\n(BTW, notice the `1e6` in the lower right corner, it is obviously not encoding at 1 to 4 ms, but at 1 000 000 to 4 000 000 ms)\\r\\n\\r\\n- Here is what it looks like with a logarithmic scale:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-log-bpp/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-log-bpp/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-log-bpp/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-log-bpp/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-log-bpp/SVT4_kaguya.webp)\\r\\n\\r\\n- **Now the speed graphs but with SSIMU2 on the y-axis instead of BPP: (logarithmic scale)**\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-log-ssimu2/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-log-ssimu2/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-log-ssimu2/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-log-ssimu2/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-log-ssimu2/SVT4_kaguya.webp)\\r\\n\\r\\n- Here are speeds graphs for preset 1 to 6 with a linear scale:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-linear-bpp/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-linear-bpp/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-linear-bpp/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-linear-bpp/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/speed-linear-bpp/SVT4_kaguya.webp)\\r\\n\\r\\nOne interpretation we can have is that **presets 2 to 4** have actually pretty close scores (pretty much the same at HQ, 2 points at max in the low quality range) but **preset 2** is **2x slower than preset 4**. The quality gap between **preset 2** and **preset 1** is even narrower but the speed penalty is also ~2x.\\r\\n\\r\\nThat makes it hard to recommend **preset 1**, while **preset 3** is in a strange middle ground between **2** and **4** where it makes little sense to choose it over those two: it\'s better to choose **preset 2** for the higher efficiency at 1.5x slower speeds, or **preset 4** for the 1.33 to 1.5x higher speeds. At least the option exists.\\r\\n\\r\\nA similar observation can be made between **preset 5** and **6**. They can be so close in scores in many samples (especially at HQ) while also being close in speeds that **preset 5** becomes rather obsolete most of the time.\\r\\n\\r\\n### TLDR\\r\\n\\r\\n**Clear quality gains can be observed as we decrease presets, until the very last one, however the effectiveness of dropping presets becomes less and less impressive the higher in quality you go.**\\r\\n\\r\\n- For instance, in worst-case scenario, we observe that (for the CRF23 to CRF8 range), __**preset 4**__ only loses at maximum **2** SSIMU2 **points** compared to __**preset -1**__ while being 50-60x faster. Though to be fair, the speed loss from __**preset 4**__ to __**preset 0**__ is \\"only\\" 5-10x for a maximum SSIMU2 difference close to **1.5 point**.\\r\\n\\r\\n- From CRF43 to CRF28, the difference between __**preset 4**__ and __**preset -1**__ can be as much as **5** SSIMU2 **points**, so lower presets become more attractive.\\r\\n\\r\\n## Tunes comparisons\\r\\n\\r\\n**In the following graphs, you may find comparisons between SVT-AV1 tunes, from the default `--tune 1` (PSNR) to the other two tunes:  `--tune 0` (VQ) and `--tune 2` (SSIM).**\\r\\n\\r\\nExcept for the tunes, `--preset 4` is set due to its good balance of quality and speed, in conjunction with the CRF values. That means everything else is default. The defaults have been mentioned earlier above.\\r\\n\\r\\n- **Let\'s compare the efficiency of every tunes:**\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Now let\'s focus on the \\"high quality\\" range (CRF8 -> 23):\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency-highq/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency-highq/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency-highq/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency-highq/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency-highq/SVT4_kaguya.webp)\\r\\n\\r\\n- And the \\"low quality\\" range (CRF28 -> 43):\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency-lowq/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency-lowq/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency-lowq/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency-lowq/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-efficiency-lowq/SVT4_kaguya.webp)\\r\\n\\r\\n- And here is the speed difference:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tunes-speed/SVT4_kaguya.webp)\\r\\n\\r\\n- Graphs comparing the tunes individually between each others will be made available soon.\\r\\n- The image comparisons will make the conclusion quite more nuanced, stay tuned (heheh) for that.\\r\\n\\r\\n### TLDR\\r\\n\\r\\n**SSIMU2 favors __tune 1 and 2__ above __tune 0__. At high quality, __tune 1 and 2__ are matched, while at low quality __tune 2__ takes the edge. __Tune 0__ is sometimes a match for the other two on certain clips and other times fare pretty badly.**\\r\\n**For some reason, __tune 0__ is quite a bit faster now, compared to 1 and 2 which are basically the same.**\\r\\n\\r\\nKeep in mind that I have observed multiple times in the past that __tune 0__ kept more fine detail and was sharper than the other tunes, at the expense of potential artifacting, like ringing and distortion. It may very well explain why the metric doesn\'t like its results. The image comparisons may give a different interpretation than what we concluded here, please stay *tuned* for these subjective comparisons.\\r\\n\\r\\n## Parameters comparisons\\r\\n\\r\\n**In the following graphs, you may find comparisons between many SVT-AV1 parameters.**\\r\\n*Additional graphs focusing on the high and low qualities will be made available later down the line*\\r\\n\\r\\n`--preset 4` is used here due to its good balance of quality and speed, in conjunction with the CRF values. That means everything else is default. The defaults have been mentioned earlier above.\\r\\n\\r\\n### `--tile-rows 1 --tile-columns 1` vs default `--tile-rows 0 --tile-columns 0`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tile-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tile-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tile-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tile-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tile-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tile-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tile-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tile-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tile-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tile-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> __tiles__ here are both slightly harmful and slower.\\r\\n\\r\\n### `--aq-mode 0` vs default `--aq-mode 2`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> Except for the Jigokuraku clip, __aq-mode 0__ is harmful in the eyes of SSIMU2, while being slower at low CRF levels, and sometimes a match or faster at high CRF levels.\\r\\n\\r\\n### `--aq-mode 1` vs default `--aq-mode 2`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode1-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode1-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode1-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode1-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode1-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode1-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode1-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode1-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode1-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/aq-mode1-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> __aq-mode 1__ fares closer to __aq-mode 2__ than __aq-mode 0__ did, both in quality and speed, but is still overall inferior according to SSIMU2\\r\\n\\r\\n### `--enable-cdef 0` vs default `--enable-cdef 1`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/cdef-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/cdef-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/cdef-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/cdef-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/cdef-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/cdef-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/cdef-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/cdef-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/cdef-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/cdef-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> According to SSIMU2, disabling CDEF barely impact efficiency. But as its a pretty demanding tool, there\'s a slight speed benefit of having it disabled too. I advise you to take these results with a grain of salt until the image comparisons, because in anime particularly, CDEF *can* be beneficial for the line-art.\\r\\n\\r\\n### `--enable-dg 0` vs default `--enable-dg 1`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dg-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dg-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dg-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dg-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dg-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dg-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dg-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dg-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dg-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dg-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> __Dynamic GoP control__ yields bit-perfect results in all clips except for Blue Lock and Jigokuraku. There is no speed benefit to disabling it except in clips where it is in use. Let\'s not jump to conclusions too easily, the image comparisons will tell if it\'s \\"safe\\" to keep the setting disabled at all times or not.\\r\\n\\r\\n### `--enable-dlf 0` vs default `--enable-dlf 1`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dlf-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dlf-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dlf-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dlf-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dlf-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dlf-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dlf-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dlf-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dlf-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/dlf-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> __Deblocking loop filter__ can be slightly beneficial in some scenarios. In reverse, it is never harmful, so it is recommended to keep it default.\\r\\n\\r\\n### `--fast-decode 1` vs default `--fast-decode 0`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/fast-decode-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/fast-decode-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/fast-decode-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/fast-decode-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/fast-decode-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/fast-decode-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/fast-decode-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/fast-decode-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/fast-decode-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/fast-decode-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> __fast-decode 1__ is pretty harmful in the Fate clip and slightly harmful in the rest. There is a speed benefit of enabling it though.\\r\\n\\r\\n### `--irefresh-type 1` vs default `--irefresh-type 2`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/irefresh-type1-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/irefresh-type1-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/irefresh-type1-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/irefresh-type1-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/irefresh-type1-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/irefresh-type1-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/irefresh-type1-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/irefresh-type1-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/irefresh-type1-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/irefresh-type1-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> Finally something interesting to analyse!\\r\\n- __irefresh-type 1__ is either a match or beneficial compared to __irefresh-type 2__ at high CRF levels.\\r\\n- __irefresh-type 1__ either wins or lose to __irefresh-type 2__ at low CRF levels depending on the clip. As such, it is NOT recommended to blindly set __irefresh-type__ to __1__ at \\"high quality\\" as it might be harmful depending on the content.\\r\\n- __irefresh-type 1__ is always slower compared to __irefresh-type 2__, so I might argue it is more safe to leave __irefresh-type__ default at \\"high quality\\" than not.\\r\\n- According to the content type of those clips, it appears that __irefresh-type 1__ may benefit *extremely grainy* content while default __irefresh-type 2__ is better suited for *cleanish* content. This needs to be confirmed with *moar* testing though.\\r\\n\\r\\n### `--lookahead 0` vs default `--lookahead -1` (auto)\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead-speed/SVT4_kaguya.webp)\\r\\n\\r\\n### `--lookahead 60` vs default `--lookahead -1` (auto)\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead60-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead60-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead60-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead60-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead60-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead60-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead60-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead60-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead60-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead60-speed/SVT4_kaguya.webp)\\r\\n\\r\\n### `--lookahead 120` (max) vs default `--lookahead -1` (auto)\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead120-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead120-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead120-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead120-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead120-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead120-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead120-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead120-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead120-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/lookahead120-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> __lookahead__ seems to behave strangely when set...\\r\\n- __lookahead 0__ shifts quality around a lot and it is difficult to draw conclusions but there\'s a clear speed drawback of disabling lookahead.\\r\\n- __lookahead 60__ is perfectly bit-perfect to every clips EXCEPT for some damn reason in Jigokuraku at CRF23\\r\\n- __lookahead 120__ is somehow also bit-perfect, but this time in every clips and every CRF levels. Both 60 and 120 don\'t see much speed differences.\\r\\n> Soooo.... this behavior is so odd I don\'t advise to set any lookahead value. Let the encoder decide.\\r\\n\\r\\n### `--enable-overlays 1` vs default `--enable-overlays 0`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/overlays-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/overlays-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/overlays-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/overlays-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/overlays-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/overlays-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/overlays-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/overlays-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/overlays-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/overlays-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> __overlays__ do not seem to either improve efficiency or performance.\\r\\n\\r\\n### `--enable-qm 1` vs default `--enable-qm 0`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> Enabling __quantization matrices__ alone increase efficiency at \\"high quality\\" with no real speed impact.\\r\\n\\r\\n### `--enable-qm 1 --qm-min 0` vs `--enable-qm 1`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-min-efficiency/SVT4_qm1_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-min-efficiency/SVT4_qm1_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-min-efficiency/SVT4_qm1_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-min-efficiency/SVT4_qm1_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-min-efficiency/SVT4_qm1_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-min-speed/SVT4_qm1_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-min-speed/SVT4_qm1_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-min-speed/SVT4_qm1_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-min-speed/SVT4_qm1_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/qm-min-speed/SVT4_qm1_kaguya.webp)\\r\\n\\r\\n> Setting __qm-min__ to __0__ on top of enabling __quantization matrices__ can be beneficial in some clips at no added compute time.\\r\\n\\r\\nI will re-tests many QMs ranges in the future, but I doubt it changed much from v1.7.0 where 0 was the most appropriate choice for most content.\\r\\n\\r\\n### `--enable-restoration 0` vs default `--enable-restoration 1`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/restoration-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/restoration-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/restoration-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/restoration-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/restoration-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/restoration-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/restoration-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/restoration-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/restoration-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/restoration-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> Even though the efficiencies are very similar, nothing is bit-perfect here. So according to SSIMU2, the __loop restoration filter__ isn\'t necessarily useful. However, just like CDEF, it\'s a pretty demanding tool, so disabling it yields some performance improvements. Let\'s take these with a grain of salt until the image comparisons.\\r\\n\\r\\n### `--scm 0` vs default `--scm 2` (content adaptive)\\r\\n\\r\\nIn all the clips, the results are bit-perfect and there is no notable performance difference.\\r\\n\\r\\n### `--scm 1` vs default `--scm 2` (content adaptive)\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![scm1-efficiency-1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/scm1-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![scm1-efficiency-2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/scm1-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![scm1-efficiency-3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/scm1-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![scm1-efficiency-4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/scm1-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![scm1-efficiency-5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/scm1-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/scm1-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/scm1-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/scm1-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/scm1-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/scm1-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> Interestingly enough, __screen content tools__ seem to improve efficiency according to SSIMU2, at the cost of a huge performance regression. After the image comparisons are published, I will conduct additional testing on this.\\r\\n\\r\\n### `--enable-tf 0` vs default `--enable-tf 1`\\r\\n\\r\\n- Efficiency graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tf-efficiency/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tf-efficiency/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tf-efficiency/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tf-efficiency/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tf-efficiency/SVT4_kaguya.webp)\\r\\n\\r\\n- Speed graphs:\\r\\n\\r\\n![1](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tf-speed/SVT4_blame.webp)\\r\\n\\r\\n![2](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tf-speed/SVT4_bluelock.webp)\\r\\n\\r\\n![3](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tf-speed/SVT4_fate.webp)\\r\\n\\r\\n![4](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tf-speed/SVT4_jigokuraku.webp)\\r\\n\\r\\n![5](https://raw.githubusercontent.com/av1-community-contributors/images/main/svt-trix-blogpost/tf-speed/SVT4_kaguya.webp)\\r\\n\\r\\n> Disabled __temporal filtering__ *can* sometimes improve efficiency slightly at \\"high quality\\", however it is very much clip dependent. It also improves performance slightly. The image comparisons will give another perspective to these results.\\r\\n\\r\\n### `--enable-tpl-la 0` vs default `--enable-tpl-la 1`\\r\\n\\r\\nIn all the clips, the results are bit-perfect and there is no notable performance difference.\\r\\n\\r\\n### `superres`:\\r\\n\\r\\nKinda lazy to make, share and comment so much graphs for something that can be told in two lines...\\r\\n\\r\\nAll superres variants are freaking useless as they:\\r\\n- do not improve efficiency\\r\\n- decrease encoding speeds\\r\\n- decrease decoding speeds when either bitrate or quality normalized.\\r\\n\\r\\n### __Early TLDR on parameters results:__\\r\\n\\r\\n***For a previous test with SVT-AV1 1.7.0 I did all parameters tests with `--preset 6 --tune 2`, now I did them with `--preset 4 --tune 1`. Mostly everything tested on v1.7.0 still stands today, but now we have more valuable data. Images comparisons are still needed to give more context to some results, so the conclusion presented here remains early as they are 100% based on SSIMU2 results and will require more analysis down the line.***\\r\\n\\r\\n**Here is a quick run down of how each parameter affect encoding:**\\r\\n- `--tile-rows --tile-columns` should never be used (except for decreasing decode complexity)\\r\\n- `--aq-mode 2` is the most efficient / fastest\\r\\n- `--enable-cdef 0` *might* improve performance at almost no efficiency loss *(needs more thorough testing)*\\r\\n- `--enable-dg` and `--enable-dlf` barely do anything\\r\\n- `--fast-decode 1` decreases efficiency, improves encoding times, and the decoding gains still need to be determined.\\r\\n- `--irefresh-type` should be kept default at high CRF values and for cleanish content at low CRF values, but can be set to 1 at low CRF values for extremely grainy content\\r\\n- `--lookahead` should be kept default\\r\\n- `--enable-overlays 1` does not improve efficiency, slight speed regression as well\\r\\n- `--enable-qm 1 --qm-min 0` should be set for increased efficiency especially at low CRF values at no perf cost\\r\\n- `--enable-restoration` barely does anything but disabling yields better performance *(needs visual confirmation)*\\r\\n- `--scm 1` screen content tools can improve efficiency with a big performance trade-off *(needs more thorough testing)*\\r\\n- `--enable-tf 0` is a mixed bag efficiency wise but improves performance\\r\\n- `superres & resize` please don\'t.\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nThe extensive benchmarking reveals that obviously the slower presets provide better efficiency, with diminishing returns past preset 2. However, preset 4 provides a good balance of quality and speed for most use cases. Presets 6 and 8 are good options for the people that find 4 to be too slow for their liking.\\r\\n\\r\\nThe default settings tend to provide good results, but some tweaks like enabling quantization matrices can further optimize efficiency. Parameters like tile encoding and super resolution modes are not beneficial. Overall, SVT-AV1 continues to be a competitive option for encoding animation in AV1, with its speed being a notable strength.\\r\\n\\r\\nFurther testing with more content samples would help solidify these findings. The image comparisons will also provide additional subjective evaluation to complement the objective metrics used here, and we can discover the potential usefulness of Tune 0 that may betray what the metrics suggest. Overall, this comprehensive deep dive should give encoders a helpful starting point for choosing settings when encoding animation with the latest SVT-AV1 1.8.0. Thanks for reading!\\r\\n\\r\\n{}"},{"id":"embedding-the-un-embeddable","metadata":{"permalink":"/blog/embedding-the-un-embeddable","source":"@site/blog/2023-10-29-embedding-the-un-embeddable copy.mdx","title":"Embedding the Un-Embeddable","description":"Revealing the secrets of those websites that allow you to embed entire movies, AV1, and videos over 500MB on Discord.","date":"2023-10-29T00:00:00.000Z","formattedDate":"October 29, 2023","tags":[{"label":"video","permalink":"/blog/tags/video"},{"label":"discord","permalink":"/blog/tags/discord"}],"readingTime":8.92,"hasTruncateMarker":true,"authors":[{"name":"Simulping","title":"Maintainer / Encoder","url":"https://github.com/Simulping","image_url":"https://avatars.githubusercontent.com/u/12994794?v=4","imageURL":"https://avatars.githubusercontent.com/u/12994794?v=4"}],"frontMatter":{"title":"Embedding the Un-Embeddable","description":"Revealing the secrets of those websites that allow you to embed entire movies, AV1, and videos over 500MB on Discord.","slug":"embedding-the-un-embeddable","authors":[{"name":"Simulping","title":"Maintainer / Encoder","url":"https://github.com/Simulping","image_url":"https://avatars.githubusercontent.com/u/12994794?v=4","imageURL":"https://avatars.githubusercontent.com/u/12994794?v=4"}],"tags":["video","discord"],"image":"/img/discord-embed-blog-image.webp","hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"Encoding Animation with SVT-AV1: A Deep Dive","permalink":"/blog/svt-av1-deep-dive"},"nextItem":{"title":"AV1 Encoding for Dummies","permalink":"/blog/av1-encoding-for-dummies"}},"content":"![Feature image](/img/discord-embed-blog-image.webp)\\r\\n**A 567.14 MB, 12 min 11 s, 2K (2,048 x 858), VP9 + Opus, 6.51 Mbps average, Blender short film \\"Cosmos Laundromat\\"**\\r\\n\\r\\n\\r\\n## A Scenario\\r\\n\\r\\nWhile chatting in your favorite Discord servers & group chats, you may see a friend send a weird link. You might even consider it suspicious on first glance. It is a video featuring an image of a movie poster with a play button that is almost begging to be clicked. Naturally, you click it.\\r\\n\\r\\n\x3c!--truncate--\x3e\\r\\n\\r\\nIt loads for a second, and to your surprise it is a full-length, 90-minute (sometimes even two hour)-long unauthorized copy of a movie. If you don\'t know exactly what is going on, you probably sit there dumbfounded as a pixel perfect HD movie plays back. You may have expected a stereotypically muddy, blocky, laggy shitpost, but this has defied your expectations.\\r\\n\\r\\n![stolen.shoes](/img/stolenshoes-puss.webp)\\r\\n\\r\\nThe truth is, there are *multiple* site that do this. Currently, there are five at the time of writing. Below is a list the ones I am currently familiar with:\\r\\n\\r\\n- https://stolen.shoes\\r\\n- https://discord.nfp.is\\r\\n- https://embeds.video\\r\\n- https://x266.mov/discord-embed\\r\\n- https://autocompressor.net/av1\\r\\n\\r\\nThe big question is, **how do they work?** Let\'s get to dissecting.\\r\\n\\r\\n## But First, a Quick Disclosure\\r\\n\\r\\nThe Codec Wiki unequivocally condemns any form of piracy, including the unauthorized distribution of copyrighted content. This blog post is intended to educate & inform. You may not use the tools discussed to infringe upon the intellectual property rights of content creators without serious legal risk. We encourage our readers to respect copyright laws & use the tools we discuss here appropriately.\\r\\n\\r\\n## How it Works\\r\\n\\r\\nThe entire scheme is actually very simple, as it is all just HTML meta tags (If you are familiar with web development, this is all a walk in the park).\\r\\n\\r\\nThe technology\'s inner working can be divided into two distinct parts. First, let\'s see how it works on the website\'s end.\\r\\n\\r\\n### The Website\'s End\\r\\nIf you view each website\'s source, you will find this specific line in each one but they may have a different order:\\r\\n\\r\\n```html\\r\\n<meta property=\\"og:image\\" content=\\"https://example.com/i/someimageforthumbnail.jpg\\">\\r\\n<meta property=\\"og:type\\" content=\\"video.other\\">\\r\\n<meta property=\\"og:video:url\\" content=\\"https://example.com/v/video.mp4\\">\\r\\n<meta property=\\"og:video:width\\" content=\\"1920\\">\\r\\n<meta property=\\"og:video:height\\" content=\\"1080\\">\\r\\n```\\r\\n\\r\\nThese are the `head` parts of HTML, which dictate metadata for the document itself such as what the website title/name is, cosmetic embed, defining the site\'s icon, etc. They are usually found in between the `<html>` and `<body>` tags. Here\'s an example of a static HTML site serving one specific video:\\r\\n```html\\r\\n<!DOCTYPE html>\\r\\n<html>\\r\\n<head>\\r\\n  <meta name=\\"viewport\\" content=\\"width=device-width, initial-scale=1.0\\">\\r\\n  <link rel=\\"shortcut icon\\" type=\\"image/x-icon\\" href=\\"../favicon.ico\\"/>\\r\\n  <title>some embed site</title>\\r\\n  <meta property=\\"og:image\\" content=\\"https://www.themoviedb.org/t/p/original/3U0vksjSY9LWe3Dqfr6xkgd3iQP.jpg\\">\\r\\n  <meta property=\\"og:type\\" content=\\"video.other\\">\\r\\n  <meta property=\\"og:video:url\\" content=\\"https://upload.wikimedia.org/wikipedia/commons/3/36/Cosmos_Laundromat_-_First_Cycle_-_Official_Blender_Foundation_release.webm\\">\\r\\n  <meta property=\\"og:video:width\\" content=\\"2048\\">\\r\\n  <meta property=\\"og:video:height\\" content=\\"858\\">\\r\\n</head>\\r\\n<body>\\r\\n  <h1>Hi</h1>\\r\\n  <p>Just your friendly neighborhood video embed site</p>\\r\\n  </body>\\r\\n</html>\\r\\n```\\r\\n\\r\\n< br />\\r\\nThese interactive sites usually deploy a live script, like a Javascript framework. Examples are NodeJS, ExpressJS, Svelte, etc. These are used to parse video and thumbnails realtime so they can be embedded on Discord (or potentially other platforms).\\r\\n\\r\\n### Discord\'s End\\r\\n\\r\\nTraditionally, Discord\'s media embedder will impose it\'s own video embed size limit (50 MiB) when a user sends a direct video link as usual. But in this case Discord will embed the thumbnail first, not the video. You could say the link \\"tricks\\" Discord by showing a \\"false face\\" first.\\r\\n\\r\\n\\r\\n\\r\\n## Strengths & Limitations\\r\\n\\r\\nAfter a combination of countless hours of observation, rigorous testing throughout the period of a year, and conversations with the sites\' creators, the current strengths & limitations of this exploit are enumerated below.\\r\\n\\r\\n#### Strengths\\r\\n\\r\\n- You can embed non-web compatible codecs such as [HEVC](https://wiki.x266.mov/docs/video/HEVC) in [MP4/MOV](https://wiki.x266.mov/docs/introduction/terminology#mp4--m4v), but the user must be using a compatible browser. [Thorium](https://thorium.rocks) or Safari version 13 or greater will work for HEVC playback.\\r\\n- There is no maximum size. You could embed a video the size of a raw Bluray, although I do not condone this unless you have the necessary legal permissions to do so or you\'re uploading a Creative Commons licensed movie like Big Buck Bunny while adhering to the restrictions of the applicable Creative Commons license. This also means you can send high bitrate gaming clips to your friends without any restrictions, assuming you already have a place to upload them.\\r\\n\\r\\n#### Limitations\\r\\n\\r\\n- You can only use [hotlinks](https://simple.wikipedia.org/wiki/Hotlinking), which means direct linking to the video itself ending in the appropriate file extension such as `.mp4`. Cloud services like Google Drive or OneDrive will not work for storage.\\r\\n- You cannot use Discord\'s CDN (cdn.discordapp.com) as the video source. I assume this is because of Discord\'s proxy blocking embeds over 50 MiB, but **only discord.nfp.is can do this**, as it **proxies cdn.discordapp.com** itself.\\r\\n- You cannot embed videos in any resolutions higher than 3840 x 2160, Discord imposes a hard limit for this on all video after it was discovered that some videos could play normally but then be maliciously scaled to ridiculous resolutions during playback to crash Discord.\\r\\n\\r\\n\\r\\n\\r\\n## Differences between Sites\\r\\n\\r\\nAs mentioned before, there are five known sites at the time of writing. They all serve the same function, but one may interest you more than another due to slight differences in features & functionality.\\r\\n\\r\\nHere are the sites, each with one noteworthy special benefit:\\r\\n\\r\\n- https://stolen.shoes - Recognition, as it is the OG.\\r\\n- https://discord.nfp.is - You can use Discord CDN as video source.\\r\\n- https://embeds.video - Immediately input video source into the URL (`https://embeds.video/https://example.com/v/video.mp4`)\\r\\n- https://x266.mov/discord-embed - Attractive domain, simple layout.\\r\\n- https://autocompressor.net/av1 - Lots of info dump, pretty advanced features.\\r\\n\\r\\nThat concludes the technical overview! Next, let\'s cover the history of this exploit.\\r\\n\\r\\n## The Lore\\r\\n\\r\\n### Dwayne\\r\\n\\r\\nIn around April of 2022, a Reddit user going by the name of u/CreativeGamer03 [posted a video on r/discordapp](https://www.reddit.com/r/discordapp/comments/u96kky/someone_sent_this_in_the_memes_channel_and_bruh) of a link where a GIF of Dwayne \\"The Rock\\" Johnson plays caption with \\"Is this a GIF or is it a video?\\" When played, a low-quality music video of Rick Astley\'s \\"Never Gonna Give You Up\\" plays.\\r\\n\\r\\nThe link used is now unfortunately [removed](https://archuser.de/the-rock).\\r\\n\\r\\n### Discovery\\r\\nOn 23rd June 2022, a Discord user *Clybius* on the AV1 Community server asked people for [VP9](https://wiki.x266.mov/docs/video/VP9) or [H.264](https://wiki.x266.mov/docs/video/AVC) videos that were over 100 MB in size. At the time the current 500 MB nitro tier did not exist. They then decided to use a 59 minute 1080p sample video of nature scenery from around the world with a thumbnail featuring a GIF of a waterfall to test the exploit. It worked.\\r\\n\\r\\nHe tried shortly afterward with [AV1](https://wiki.x266.mov/docs/video/AV1). Eureka, it also worked:\\r\\n\\r\\n![AV1](/img/clybius-av1.webp)\\r\\n\\r\\nClybius confirmed that this could be patched if discovered. He cites having had the idea from the Dwayne Johnson example above, but forgetting about it for a couple of months. So, it seems this entire concept stemmed from a silly rickroll.\\r\\n\\r\\n![Dwayne](/img/clybius-dwayne.webp)\\r\\n\\r\\n### The Experiments & Interactive Site\\r\\n\\r\\nAfter the discovery of AV1 embedding, experimentation brought about the discovery that *any* video codec will work as long as the user can decode/play the codec and the container/extension is an MP4, MOV, or WebM. These are all traditionally web-compatible containers. If you\'re interested in learning about containers, please see the [Containers](https://wiki.x266.mov/docs/introduction/terminology#container) section on the [Terminology](https://wiki.x266.mov/docs/introduction/terminology) page.\\r\\n\\r\\nThis applies to HEVC, ProRes, [xHE-AAC](https://wiki.x266.mov/docs/audio/AAC#xhe-aac), and other bizarre codecs that are rarely seen on the Web.\\r\\n\\r\\nWhile experimentating, Clybius converted one their idle domains `stolen.shoes` into an interactive embedder that provided a textbox for a video URL, a thumbnail URL, a width value, & a height value for the desired video. This would be the first website for Discord embedding.\\r\\n\\r\\n### Virality\\r\\n\\r\\nIt\'s not long before people outside of the AV1 Community discovered `stolen.shoes`, and its popularity increased rapidly. Its use usually involved the illicit distribution of full-length, unauthorized copies of movies; this sometimes happened very shortly after some movies were released. There were a couple notable instances of this happenening that caused quite the stir online each time.\\r\\n\\r\\n- The first instance featured the DreamWorks sequel of \\"Puss in Boots (2011)\\", \\"Puss in Boots: The Last Wish (2022)\\". A 1080p video sourced from a streaming site was the first wake up call that attracted attention to the existence of these embed sites. This example used `stolen.shoes`.\\r\\n\\r\\n![puss](/img/stolenshoes-puss.webp)\\r\\n\\r\\n- The second instance was when highly-anticipated animated film \\"The Super Mario Bros. Movie (2023)\\" produced by Illumination, Universal Studios, and Nintendo was spread around Discord. It was first spotted as a Cam (A camera recording by someone in theaters), then as it went out on streaming services a different link appeared but spread faster and with upgraded 1080p quality. Both used `stolen.shoes` as the embed site.\\r\\n\\r\\n![mario](/img/stolenshoes-mario.webp)\\r\\n\\r\\n- The third instance is very recent as of the day this was posted. A streaming-service sourced \\"Five Nights at Freddy\'s (2023)\\" was spread around since the movie released both in theaters and streaming service (Peacock) day one, and it gained steam extremely fast as most people had not seen it yet. Currently, this illegal novelty is gaining [hundreds of upvotes within the r/discordapp subreddit](https://www.reddit.com/r/discordapp/comments/17hx45y/is_discordnfp_an_ip_grabber/). The copy seems to be a compressed 720p encode. This example used `discord.nfp.is`.\\r\\n\\r\\n![fnaf](/img/discordnfpis-fnaf.webp)\\r\\n\\r\\nNote the ones listed here are the ones that I saw become extremely popular. There may be lesser known links that have been spread around privately or just did not cause enough noise for me to notice. Some less popular examples I\'ve noticed, featuring more illicit copyrighted content distribution: \\r\\n- Top Gun Maverick (2022)\\r\\n- The SpongeBob trilogy (2005/2015/2020)\\r\\n- Spider-Man: Across the Spider-Verse (2023)\\r\\n\\r\\n\\r\\n## Closing\\r\\n\\r\\nThe ability to embed unusually large videos on Discord has enabled both positive and negative use cases. On the one hand, it allows high-quality content to be shared easily among friends. However, it has also facilitated mass copyright infringement by empowering virtually anyone with a Discord accound to freely spread pirated movies.\\r\\n\\r\\nWhile this is fascinating from a technical perspective, embedding techniques like these tread a fine ethical line. As with anything, it is important to be mindful of how our actions affect others, and I should remind everyone that content creators deserve to be compensated for their work. As users, we should support them by accessing their content via legitimate platforms.\\r\\n\\r\\nIt is hard to say how long this exploit will continue to be usable. Instead of enabling piracy, which may cause Discord to be more likely to patch this exploit if they see it as a serious threat, let\'s instead use these capabilities responsibly to share our own creations, gaming highlights, and other media which we can share legally. Given some thoughtfulness, perhaps we can find a fair balance between respecting copyright law and appeasing Discord\'s sensibilities while allowing some creative flexibility on the platform.\\r\\n\\r\\nThank you for reading this blog post, I hope you learned something!"},{"id":"av1-encoding-for-dummies","metadata":{"permalink":"/blog/av1-encoding-for-dummies","source":"@site/blog/2023-09-03-av1-for-dummies.mdx","title":"AV1 Encoding for Dummies","description":"This guide will show you how to encode in AV1 the *right* and *optimal* way.","date":"2023-09-03T00:00:00.000Z","formattedDate":"September 3, 2023","tags":[{"label":"video","permalink":"/blog/tags/video"},{"label":"compression","permalink":"/blog/tags/compression"}],"readingTime":15.865,"hasTruncateMarker":true,"authors":[{"name":"Simulping","title":"Maintainer / Encoder","url":"https://github.com/Simulping","image_url":"https://avatars.githubusercontent.com/u/12994794?v=4","imageURL":"https://avatars.githubusercontent.com/u/12994794?v=4"},{"name":"Gianni Rosato","title":"Maintainer","url":"https://github.com/gianni-rosato","image_url":"https://avatars.githubusercontent.com/u/35711760?v=4","imageURL":"https://avatars.githubusercontent.com/u/35711760?v=4"}],"frontMatter":{"title":"AV1 Encoding for Dummies","description":"This guide will show you how to encode in AV1 the *right* and *optimal* way.","slug":"av1-encoding-for-dummies","authors":[{"name":"Simulping","title":"Maintainer / Encoder","url":"https://github.com/Simulping","image_url":"https://avatars.githubusercontent.com/u/12994794?v=4","imageURL":"https://avatars.githubusercontent.com/u/12994794?v=4"},{"name":"Gianni Rosato","title":"Maintainer","url":"https://github.com/gianni-rosato","image_url":"https://avatars.githubusercontent.com/u/35711760?v=4","imageURL":"https://avatars.githubusercontent.com/u/35711760?v=4"}],"tags":["video","compression"],"image":"/img/compare-guide.webp","hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"Embedding the Un-Embeddable","permalink":"/blog/embedding-the-un-embeddable"},"nextItem":{"title":"Reducing Image Load Online","permalink":"/blog/site-optimization"}},"content":"This guide will show you how to encode in AV1 the *right* and *optimal* way. Yes, you using standalone ``libaom``, ``libsvtav1``, and ``librav1e`` from FFmpeg or even piping ``yuv4mpeg`` into **mainline** aomenc are all unoptimal.\\r\\n\\r\\n\x3c!--truncate--\x3e\\r\\n\\r\\n\\r\\n![Compare](/img/compare-guide.webp)\\r\\n\\r\\nIn this guide, we\'ll be installing Av1an for chunked encoding and infinite threading, because the current state of AV1 encoders, except for [SVT-AV1](https://wiki.x266.mov/docs/encoders/SVT-AV1), unfortunately lacks threading and will only use very low amount of cores, which hampers speeds. The only caveat to this approach is **RAM consumption**, encoding 2160p (4K) with [aomenc](https://wiki.x266.mov/docs/encoders/aomenc) with 4 workers could take upwards of **16GB** of RAM! So do keep this in mind.\\r\\n\\r\\n## Installing the Tools\\r\\n\\r\\nGiven all of the different operating systems that people use on a day to day basis and the various different encoding workflows that exist, there are a number of ways to do this.\\r\\n\\r\\n**Jump to**: [Windows](#microsoft-windows) | [macOS](#macos) | [Linux](#linux)\\r\\n\\r\\n## Microsoft Windows\\r\\n\\r\\n### The GUI Way\\r\\n1. Install [NMKODER](https://github.com/n00mkrad/nmkoder) which is a GUI front-end to av1an with all dependencies installed.\\r\\n2. You\'re done, you can skip to the encoding part\\r\\n\\r\\n:::danger Almost abandonware\\r\\nSince Nmkoder already ships everything by default and its last release was 29th March 2022. You need to manually update all encoders and tools to get better encoding speeds. Missing out on updates will result in your encodes being sub-optimal.\\r\\n:::\\r\\n\\r\\n### The WSL2 Way\\r\\n\\r\\n*(Recommended)*\\r\\n\\r\\nIf you\'re not already familiar with WSL2, the The Windows Subsystem for Linux (WSL) is a feature of the Windows operating system that allows you to run a Linux file system, along with Linux command-line tools and GUI apps, directly on Windows. This lets Linux distributions run on bare metal without managing any virtual machines, so encoding performance is very good.\\r\\n\\r\\nThe easiest way to encode with WSL2 is to use [rAV1ator CLI](https://wiki.x266.mov/docs/utilities/rav1ator-cli), an interactive TUI for [Av1an](https://wiki.x266.mov/docs/utilities/av1an). An ArchWSL2 installation tutorial is provided [here](https://wiki.x266.mov/docs/utilities/rav1ator-cli#windows).\\r\\n\\r\\n### The Automated Way\\r\\n\\r\\nThere is now a batch script for automating the install process, which can be found [here](https://github.com/Hishiro64/av1an-win-script). The instructions are in the README file.\\r\\n\\r\\n:::caution\\r\\nThe script will download outdated version encoders and tools such as `aom-av1-psy` and MKVToolNix v76.0, if you are fine with these you can proceed.\\r\\n:::\\r\\n\\r\\n### The Manual Way\\r\\n\\r\\n1. Install **Python 3.10.x, this will change so consult from the** [Vapoursynth website](http://www.vapoursynth.com/doc/installation.html) **if you\'re reading this from the future** from [here](https://www.python.org/downloads/windows/) and select \\"Windows Installer 64-bit\\". Upon installation check the tick for adding Python to PATH like so\\r\\n![Python PATH](/img/python-path.webp))\\r\\n\\r\\n2. Download and install Vapoursynth from [here](https://github.com/vapoursynth/vapoursynth/releases) and select \\"VapourSynth64-RXX.exe\\"\\r\\n3. Open the terminal and type ``vsrepo.py install lsmas ffms2`` to install some plugins for Av1an to work.\\r\\n4. Download MKVToolNix from [here](https://mkvtoolnix.download/downloads.html#windows), select \\"mkvtoolnix-64bit-XX.X.X-setup.exe\\", and install **(Also available on winget!)**\\r\\n5. Download Av1an from [here](https://github.com/master-of-zen/Av1an/releases) (SELECT LATEST AND CLICK THE \\"ASSETS\\" DROPDOWN)\\r\\n6. Download **shared libraries** FFmpeg from [gyan.dev](https://www.gyan.dev/ffmpeg/builds)\\r\\n7. Download a pre-built fork of Aomenc ([aom-av1-lavish](https://github.com/Clybius/aom-av1-lavish/tree/Endless_Merging)) which has neat stuff such as sane defaults, new tunes, optimizations, etc. This can be downloaded for Windows [here](https://autumn.revolt.chat/attachments/download/-2EiZW1edcT9anApFZ1PJBEber-pJ6z02NiQBjbr28) *(Current as of Sept 6, 2023)*\\r\\n:::info\\r\\nIf you opt to compile aomenc yourself, you can view the instructions on how to do that [here](https://wiki.x266.mov/docs/encoders/aomenc/#installation).\\r\\n:::\\r\\n8. Move Av1an, FFmpeg **(Including the FFmpeg DLLs)**, and aomenc to somewhere preferable, eg ``C:\\\\Encoding``.\\r\\n9. Add the folder **AND MKVTOOLNIX INSTALLATION FOLDER** to the [Windows PATH environment](https://www.maketecheasier.com/what-is-the-windows-path/).\\r\\n\\r\\n\\r\\n## macOS\\r\\n\\r\\nmacOS is very similar to Linux, although there aren\'t any GUI tools for AV1 encoding that I can comfortably recommend.\\r\\n\\r\\n**Homebrew + Macports for Av1an + rav1e:**\\r\\n*Note that some commands may have to be run with `sudo`, which I won\'t explicitly include for security reasons.*\\r\\n\\r\\nInstalling the Homebrew package manager is a well documented process at this point:\\r\\n```bash\\r\\n/bin/bash -c \\"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\\"\\r\\n```\\r\\n\\r\\nAs is installing MacPorts. Install the relevent `.pkg` for your macOS version from the MacPorts Project website:\\r\\n[www.macports.org/install.php](https://www.macports.org/install.php)\\r\\n\\r\\nNow, you can run the following commands:\\r\\n```bash\\r\\nbrew update && brew upgrade\\r\\nbrew install rav1e aom mkvtoolnix ffmpeg\\r\\n# Usually you must run MacPorts commands for package installations as root\\r\\nport upgrade outdated\\r\\nport install av1an\\r\\n```\\r\\n\\r\\nThis is the easiest way to get everything set up & working to produce AV1 video with `rav1e` or mainline `aomenc` & Av1an. You can check that things are installed by running the following commands & parsing their output:\\r\\n```bash\\r\\n% av1an --version\\r\\nav1an 0.4.1-unstable (rev e10880d) (Release)\\r\\n\\r\\n* Compiler\\r\\n  rustc 1.70.0 (LLVM 16.0)\\r\\n\\r\\n* Target Triple\\r\\n  aarch64-apple-darwin\\r\\n\\r\\n* Date Info\\r\\n  Commit Date:  2023-06-25\\r\\n\\r\\n* VapourSynth Plugins\\r\\n  systems.innocent.lsmas : Not found\\r\\n  com.vapoursynth.ffms2  : Not found\\r\\n```\\r\\n```bash\\r\\n% rav1e --version | grep \\"release\\" -C 1      \\r\\nrav1e 0.6.6 () (release)\\r\\nrustc 1.69.0 (84c898d65 2023-04-16) (built from a source tarball) aarch64-apple-darwin\\r\\n```\\r\\n```bash\\r\\n% aomenc --help | grep \\"AOMedia\\" -C 3\\r\\n\\r\\nIncluded encoders:\\r\\n\\r\\n    av1    - AOMedia Project AV1 Encoder 3.6.1 (default)\\r\\n\\r\\n        Use --codec to switch to a non-default encoder.\\r\\n```\\r\\n\\r\\nNotice `systems.innocent.lsmas : Not found` in the Av1an output. This means you won\'t be able to use the lsmash chunking method through vapoursynth & may instead have to rely on hybrid chunking, through `-m hybrid`. This is slower & takes up disk space while encoding, but still works. A sample Av1an command with this basic installation may look like this:\\r\\n\\r\\n```bash\\r\\nav1an -i \\"input\\" -y --resume --verbose --split-method av-scenechange -m hybrid -c mkvmerge -e rav1e --force -v \\" --tiles 8 -s 4 --quantizer 80 --no-scene-detection\\" --photon-noise 7 --chroma-noise --pix-format yuv420p10le -w 8 -o \\"output.mkv\\"\\r\\n```\\r\\n\\r\\n**Building From Source**\\r\\n\\r\\nIf you want lsmash support, aom-av1-lavish instead of mainline, or anything else that isn\'t covered by the more basic installation, you\'ll have to compile from source. Things are very similar to Linux, with a few oddities:\\r\\n\\r\\n- macOS sometimes doesn\'t have a `/usr/local/bin` by default. You can fix this by doing `mkdir /usr/local/bin`.\\r\\n- Homebrew installs *everything* in its own directory structure. If you\'re building things from source that rely on libraries from vapoursynth, zimg, lsmash, etc, make sure to copy them from `/opt/homebrew/lib` to `/usr/local/lib`. Finding them is a matter of `ls | grep \\"keyword\\"` & copying what looks reasonable to be associated with the tool you\'re using.\\r\\n- Building most things from source will have instructions for \\\\*nix which work for both macOS & Linux. Even if it says Linux, there\'s a good chance it\'ll work on macOS as well, & it is always worth trying Linux build instructions on Mac. I won\'t be going through building every encoding tool & dependency from source, as it is generally much more intuitive than Windows, but building Av1an is worth detailing here just as an example.\\r\\n```bash\\r\\nbrew install git rust nasm\\r\\ngit clone https://github.com/master-of-zen/Av1an\\r\\ncd Av1an\\r\\nRUSTFLAGS=\\"-C target-cpu=native\\" cargo build --release\\r\\ncd .. && cd target/release\\r\\ncp av1an /usr/local/bin\\r\\n```\\r\\n\\r\\n**More Difficult: Building aom-av1-lavish from Source**\\r\\n\\r\\nIf you want to make the most out of your hardware & eke out every last drop of quality, it may be worth building aom-av1-lavish from source. The first step is to clone it from the Endless Merging branch:\\r\\n```bash\\r\\ngit clone https://github.com/Clybius/aom-av1-lavish -b Endless_Merging\\r\\ncd aom-av1-lavish\\r\\n```\\r\\nNow, you need to make some manual changes to the source code until Clybius merges [this commit](https://github.com/Clybius/aom-av1-lavish/pull/1/files).\\r\\n- Add the line `#include \\"aq_variance.h\\"` at line 19 in `av1/encoder/encodeframe_utils.c`\\r\\n- Comment out line 2546 in `av1/encoder/speed_features.c`. This line is `const int qindex_thresh_cdef_sf_s1_s3_l2[2] = { 92, 48 };` & becomes `// const int qindex_thresh_cdef_sf_s1_s3_l2[2] = { 92, 48 };`.\\r\\n\\r\\nNow you can continue to build according to the Linux instructions below. Obviously you\'ll need cmake, which you can install with homebrew along with any other tools you may need. While still in the `aom-av1-lavish` directory:\\r\\n```bash\\r\\nmkdir -p aom_build && cd aom_build\\r\\ncmake .. -DBUILD_SHARED_LIBS=0 -DENABLE_DOCS=0 -DCONFIG_TUNE_BUTTERAUGLI=0 -DCONFIG_TUNE_VMAF=0 -DCONFIG_AV1_DECODER=0 -DENABLE_TESTS=0 -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=\\"-flto -O3 -march=native\\" -DCMAKE_C_FLAGS=\\"-flto -O3 -march=native -pipe -fno-plt\\" -DCMAKE_LD_FLAGS=\\"-flto -O3 -march=native\\"\\r\\nmake -j$(nproc)\\r\\n# This may need to be run as root:\\r\\nmake install\\r\\n```\\r\\n\\r\\nNow you can run `aomenc --help | grep \\"AOMedia\\" -C 3` to see if lavish installed. If you\'re getting the same output as above, you may need to copy the `aomenc` executable to `/opt/local/bin`, `/usr/local/bin`, & `/opt/homebrew/bin` if you already installed mainline aomenc. Running the version info command again, the correct output should look something like this:\\r\\n```bash\\r\\n% aomenc --help | grep AOMedia -C 3\\r\\n\\r\\nIncluded encoders:\\r\\n\\r\\n    av1    - AOMedia Project AV1 Encoder Psy v3.6.0 (default)\\r\\n\\r\\n        Use --codec to switch to a non-default encoder.\\r\\n```\\r\\n\\r\\nNotice how it says `AOMedia Project AV1 Encoder Psy` instead of `AOMedia Project AV1 Encoder`. You should be all set after this to start using aom-av1-lavish & following the current parameter meta as outlined below.\\r\\n\\r\\n## Linux\\r\\n\\r\\n:::info\\r\\nYet again, try using Arch. It\'s way easier.\\r\\n:::\\r\\n\\r\\n### The GUI Way\\r\\n\\r\\n- Install [Aviator](https://github.com/gianni-rosato/aviator) ([SVT-AV1](https://wiki.x266.mov/docs/encoders/SVT-AV1) + [FFmpeg](https://wiki.x266.mov/docs/utilities/FFmpeg)) or [rAV1ator](https://giannirosato.com/blog/post/aviator-1/) basically same thing but [Av1an](https://wiki.x266.mov/docs/utilities/av1an.mdx) + [rav1e](https://wiki.x266.mov/docs/encoders/rav1e). Both are only available as [Flatpaks](https://beta.flathub.org/apps/net.natesales.Aviator). Keep in mind Aviator ships with **SVT-AV1** and rAV1ator with **rav1e** instead of aomenc/AOM-AV1, which I will not be covering here.\\r\\n\\r\\n### The TUI Way\\r\\n\\r\\n*(Recommended)*\\r\\n\\r\\n- Install [rav1ator-cli](https://wiki.x266.mov/docs/utilities/rav1ator-cli), a TUI for using Av1an meant to be easy to use. Much more flexible than the GUI options & can work with a number of encoders. See [this page](https://wiki.x266.mov/docs/utilities/rav1ator-cli/#installation) for more info. Can be easily used on any distro.\\r\\n\\r\\n### The Compiling Route\\r\\n\\r\\n#### Ubuntu\\r\\n\\r\\nThe guide below is targeted towards 22.04, packages and other things may be different on other versions. First Install Rust via `rustup` first, as apt version of Rust is severely outdated, then you can continue.\\r\\n\\r\\nInstall dependencies:\\r\\n```bash\\r\\nsudo apt install wget python unzip unrar build-essential meson autoconf automake libtool git nasm yasm python3-dev python3-pip cython3 libass-dev libqt5websockets5-dev libfftw3-dev libtesseract-dev ffmpeg libavcodec-dev libavformat-dev libswscale-dev libavutil-dev libswresample-dev libmediainfo-dev mkvtoolnix mediainfo perl nasm yasm git cmake libavutil-dev libavcodec-dev libavformat-dev libavdevice-dev libavfilter-dev libswscale-dev libswresample-dev libpostproc-dev llvm libclang-dev libssl-dev\\r\\n```\\r\\n\\r\\nInstall l-smash:\\r\\n```bash\\r\\ngit clone https://github.com/l-smash/l-smash.git\\r\\ncd l-smash\\r\\n./configure --enable-shared --extra-cflags=\\"-march=native\\"\\r\\nmake -j$(nproc)\\r\\nsudo make install\\r\\n```\\r\\n\\r\\nInstall zimg:\\r\\n```bash\\r\\ngit clone --recursive https://github.com/sekrit-twc/zimg.git\\r\\ncd zimg\\r\\n./autogen.sh\\r\\n./configure\\r\\nmake -j$(nproc)\\r\\nsudo make install\\r\\n```\\r\\n\\r\\nInstall ImageMagick:\\r\\n```bash\\r\\ngit clone https://github.com/ImageMagick/ImageMagick\\r\\ncd ImageMagick\\r\\n./configure\\r\\nmake -j$(nproc)\\r\\nsudo make install\\r\\n```\\r\\n\\r\\nInstall Vapoursynth R63:\\r\\n```bash\\r\\nwget https://github.com/vapoursynth/vapoursynth/archive/refs/tags/R63.zip\\r\\nunzip R63.zip\\r\\ncd vapoursynth-R63\\r\\n./autogen.sh\\r\\n./configure CFLAGS=\\"-march=native\\" CXXFLAGS=\\"-march=native\\" --libdir=/usr/lib\\r\\nmake -j$(nproc)\\r\\nsudo make install\\r\\nsudo mkdir /usr/lib/vapoursynth\\r\\nsudo ldconfig\\r\\n```\\r\\nThe plugin directory will be located in `/usr/lib/vapoursynth`.\\r\\n\\r\\n\\r\\nInstall L-SMASH-Works Vapoursynth Plugin:\\r\\n```bash\\r\\ngit clone https://github.com/AkarinVS/L-SMASH-Works -b ffmpeg-4.5\\r\\ncd L-SMASH-Works/VapourSynth && mkdir build && cd build\\r\\nmeson .. --optimization=3 --default-library=static -Db_lto=true -Dc_args=\\"-march=native\\" -Dcpp_args=\\"-march=native\\"\\r\\nninja -j$(nproc)\\r\\nsudo cp libvslsmashsource.so /usr/lib/vapoursynth/\\r\\n```\\r\\n\\r\\n:::danger\\r\\nL-SMASH-Works doesn\'t work on **aarch64**, it is recommended to use other plugins instead.\\r\\n:::\\r\\n\\r\\nInstall FFMS2 Vapoursynth Plugin:\\r\\n```bash\\r\\ngit clone https://github.com/FFMS/ffms2\\r\\ncd ffms2\\r\\n./autogen.sh\\r\\n./configure CFLAGS=\\"-O3 -march=native\\" CXXFLAGS=\\"-O3 -march=native\\"\\r\\nmake -j$(nproc)\\r\\nsudo cp src/core/.libs/libffms2.so src/core/.libs/libffms2.so.5 src/core/.libs/libffms2.so.5.0.0 /usr/lib/vapoursynth\\r\\n```\\r\\n\\r\\nInstall Av1an:\\r\\n```bash\\r\\ngit clone https://github.com/master-of-zen/Av1an\\r\\ncd Av1an\\r\\nRUSTFLAGS=\\"-C target-cpu=native\\" cargo build --release\\r\\nsudo cp target/release/av1an /usr/local/bin\\r\\n```\\r\\n\\r\\nWhen there\'s no errors, proceed to compiling `aom-av1-lavish`.\\r\\n\\r\\n### Arch\\r\\n\\r\\nInstall dependencies:\\r\\n```bash\\r\\nsudo pacman -S vapoursynth ffmpeg av1an mkvtoolnix-gui git perl cmake ninja meson nasm vapoursynth-plugin-lsmashsource ffms2\\r\\n```\\r\\n\\r\\nyou\'re done, proceed.\\r\\n\\r\\n#### Compiling aom-av1-lavish\\r\\n``` bash\\r\\ngit clone https://github.com/Clybius/aom-av1-lavish -b Endless_Merging\\r\\ncd aom-av1-lavish && mkdir -p aom_build && cd aom_build\\r\\ncmake .. -DBUILD_SHARED_LIBS=0 -DENABLE_DOCS=0 -DCONFIG_TUNE_BUTTERAUGLI=0 -DCONFIG_TUNE_VMAF=0 -DCONFIG_AV1_DECODER=0 -DENABLE_TESTS=0 -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=\\"-flto -O3 -march=native\\" -DCMAKE_C_FLAGS=\\"-flto -O3 -march=native -pipe -fno-plt\\"\\r\\nmake -j$(nproc)\\r\\nsudo make install\\r\\n```\\r\\n\\r\\n## Encoding\\r\\n\\r\\nThe moment you\'ve all been waiting for, let\'s just get into it. Here\'s an example *recommended* parameter as of now (09/03/23) [MM/DD/YY]:\\r\\n```bash\\r\\nav1an -x 300 -i input.mkv -w 4 -e aom -c mkvmerge --resume -m lsmash --photon-noise=10 --set-thread-affinity=2 --verbose -a \\" -an \\" -f \\" -an \\" -v \\" --bit-depth=10 --cpu-used=4 --end-usage=q --cq-level=24 --threads=2 --tile-columns=0 --tile-rows=0 --lag-in-frames=64 --tune-content=psy --tune=ssim --enable-keyframe-filtering=1 --disable-kf --kf-max-dist=9999 --enable-qm=1 --deltaq-mode=0 --aq-mode=0 --quant-b-adapt=1 --enable-fwd-kf=0 --arnr-strength=1 --sb-size=dynamic --enable-dnl-denoising=0 \\" -o \\"output.mkv\\"\\r\\n```\\r\\n\\r\\n:::info Parameter Meta\\r\\nIt is strongly recommended to join the [AV1 Discord server](https://discord.gg/vpREHAvYvh) to get the latest updates on what to use and which to set, as it\'s the only easily reachable place for everything AV1 & encoding tips in general.\\r\\n:::\\r\\nNow let\'s dissect it one-by-one\\r\\n\\r\\n**Av1an parameters:**\\r\\n\\r\\n- ``-i`` Input.\\r\\n\\r\\n- ``-x 300`` Sets scene split length to 300 frames, you can increase it for more quality at the tradeoff of video seekability.\\r\\n\\r\\n- ``-w 4`` Specifies the amount of \\"workers\\" or amount of encoders working on the video.\\r\\n\\r\\n- ``--verbose`` Sets logging to verbose.\\r\\n\\r\\n- ``--resume`` Resumes the encode even when you haven\'t encoded yet. I strongly recommend leaving this if you resume a lot since you can accidentally delete your whole progress (There\'s no delete confirmation feature.. yet) if you \\"resumed\\" without the parameter in place.\\r\\n\\r\\n- ``-e aom`` Specifies we\'re using aomenc encoder which should be the default option.\\r\\n\\r\\n- ``-c mkvmerge`` Specifies we\'re using mkvmerge (MKVToolNix) to concatenate the parts when done, you can specify with ffmpeg if you want to but this is the best method.\\r\\n\\r\\n- ``-m lsmash`` Specifies we\'re using l-smash (Vapoursynth plugin) to split the videos, this is also the best method because ffms2 causes video lag (Tested a year ago, might change now) and other methods just suck (Slow and not worth it, learned the hard way). You can attempt to use ffms2 when inputting VC-1 videos as it is not possible with l-smash (Or convert it to lossless with x264 qp 0).\\r\\n\\r\\n- ``-f \\" -an \\"`` ``-f`` Stands for ffmpeg parameters, ``-an`` is to remove all audio since its better to encode and merge it separately. To crop use ``-f \\" -an -vf crop=1920:800 \\"`` for example to crop the video to 1920x800.\\r\\n\\r\\n- ``-v \\" \\"`` Is where you put the encoder\'s parameters in.\\r\\n\\r\\n- ``-a \\" -an \\"`` FFmpeg audio encoding options, we\'re removing it cause we can always add it later. But if you want to, you can also encode directly. Here\'s an example for encoding to Opus using libopus assuming stereo: `-a \\" -c:a libopus -b:a 128k \\"`.\\r\\n\\r\\n- ``--photon-noise=10`` AV1 grain synthesis, which is a technique where the encoder puts fake grain in so it looks more natural and potentially hiding video artifacts (cause grain is hard to encode and explodes bitrate usage because of their randomness), 5-8 for almost none to little grain, 10-14 for medium, 15+ heavy, 20+ extremely heavy, 30+ for extremely grainy 90s live action films.\\r\\n\\r\\n- ``--set-thread-affinity=2`` Pins the thread to the encoder, aligns with ``--threads=2`` in the encoder parameter so set them accordingly.\\r\\n\\r\\n\\r\\n**aomenc parameters:**\\r\\n- ``--bit-depth=10`` We\'re using 10bit because it makes the video smaller and reduces [banding](https://developer.mozilla.org/en-US/docs/Web/Media/Formats/Video_codecs#contouring).\\r\\n\\r\\n- ``--cpu-used=4`` This is the preset which ranges from 0-9, you can go to 3 if you want more efficiency, 2 if you have a lot of time, 4 is the sweet spot, and 6 if you want speed. Don\'t go above 6 (Worst efficiency) or even 0 (It would take WEEKS to finish).\\r\\n\\r\\n- ``--end-usage=q --cq-level=24`` This specifies that we are going to use a knockoff version of CRF level similar to x264/x265 encoders, in this case CRF 24.\\r\\n\\r\\n- `--threads=2` Sets the amount of threads the encoder can use, aligns with `--set-thread-affinity` in Av1an.\\r\\n\\r\\n- ``--tile-columns=0 --tile-rows=0`` This is the tiles options, where the encoder splits the videos into tiles to encode faster, see the image below (Yellow lines):\\r\\n<picture>\\r\\n    <source srcset=\\"https://raw.githubusercontent.com/av1-community-contributors/images/main/tiling_av1.avif?token=GHSAT0AAAAAACEZPDXIZARY5MGSTJW4SI22ZHY636A\\" type=\\"image/avif\\" />\\r\\n    <img src=\\"https://autumn.revolt.chat/attachments/HwhZjoDsdzLZsJM2mjzX7lEDmJn1xcYNdrQqmOxPYW/tiling_av1.jpeg\\" alt=\\"Tiling\\" width=\\"1280\\" height=\\"768\\" loading=\\"lazy\\" />\\r\\n</picture> \\r\\n\\r\\n:::note Tile usage\\r\\nDo NOT use tiles for 1080p and below, use 1 ``tile-columns`` at 1440p (2K), 2 ``tile-columns`` and 1 ``tile-rows`` for 2160p (4K)\\r\\n:::\\r\\n\\r\\n- ``--lag-in-frames=64`` Similar to x264/x265 `rc-lookahead`. Sets a number of frames to look ahead for frametype and ratecontrol, allowing for better compression decision making. Setting to a value greater than 64 is generally not considered useful.\\r\\n \\r\\n- ``--aq-mode`` adaptive quantization mode, 0 is better most of the time\\r\\n\\r\\n- ``--tune-content=psy --tune=ssim`` As the name suggests they are tunes that affect the video output, for the better, and for the worst\\r\\n\\r\\n:::info Tunes to use\\r\\nSet ``tune-content`` to ``animation`` if you\'re encoding above ``cq-level=30`` A.K.A lower quality, despite it\'s name\\r\\nSet ``tune-content`` to ``psy`` for everything else, **do not use if you encode above ``cq-level=30``**\\r\\nFor ``tune``, this is a bit tricky. For now, the meta seems to be ``ssim``, but back then it was ``lavish`` which is considered THE best tune because it\'s based on [butteraugli](https://github.com/google/butteraugli). Now it\'s fallen behind because its more blurry than ``ssim``, and before that it was ``butteraugli``, and then ``ipq_vmaf_psy``, and finally just ``ipq``. \\r\\nIf you use any of the VMAF tunes, **you need to specify ``--vmaf-model-path=`` to where you put it**.\\r\\n:::\\r\\n\\r\\n- ``--enable-keyframe-filtering=1`` We\'re setting it to 1 because of compatibility reasons, 2 is more efficient but there are seeking issues and FFmpeg for some reason can\'t input it.\\r\\n\\r\\n- ``--sb-size=dynamic`` Allows the encoder to use 128x128 block partitioning besides 64x64 which gives an efficiency boost, ignore it.\\r\\n\\r\\n- ``--deltaq-mode`` set to 0 because its just better.\\r\\n\\r\\n- ``--arnr-strength=1`` Controls how strong the filtering will be, 1 is good for 3D Pixar CGI-like and 2D animation, use 4 if you\'re doing live action content. Using maximum at higher bitrates would just result in a blurry mess.\\r\\n\\r\\n- ``--disable-kf --enable-fwd-kf=0`` We\'re disabling keyframes cause **Av1an already did scene detection, so we wont have to.**. And it speeds things up.\\r\\n\\r\\n- ``--kf-max-dist=9999`` Maximum keyframe interval, we\'re setting it at the highest possible value since av1an\'s scene detection keyframe interval is already 240 by default\\r\\n\\r\\n- ``--enable-chroma-deltaq=1 --enable-qm=1 --quant-b-adapt=1`` Parameters that give you free efficiency boost.\\r\\n\\r\\n- ``--enable-dnl-denoising=0`` Disables the encoder\'s built-in denoising technique when grain synthesis is enabled, you can optionally set it to 1 when you have a pretty noisy video since it works quite well.\\r\\n\\r\\n\\r\\n:::info Concatenation Error on Linux\\r\\nRun ``ulimit -n 200000``, resume, and it should concatenate just fine. If it still errors, head to the encode directory > encode, and run ``mkvmerge @../options.json``\\r\\n:::\\r\\n\\r\\n\\r\\n## Merging Everything\\r\\n\\r\\nOnce you\'re done just encode your audio using ffmpeg (or just passthrough it), subtitles should be carried along with your video output, and merge them in MKVToolNix! Don\'t want Matroska files? That\'s fine, you can use FFmpeg or MP4Box to output into `mp4`, just keep in mind that PGS/SUP/VOBSUB subtitles are not supported and Opus audio support is still experimental.\\r\\n\\r\\n\\r\\n## Tips & Tricks\\r\\n\\r\\n- `--denoise-noise-level=10` Alternative to `photon-noise`, slower than photon-noise and is the OG grain synthesis method, performs okay and just serves as an alternative. Don\'t attempt to use it at high values (>12) since it creates noticeable grain patterns.\\r\\n\\r\\n- `--arnr-maxframes` to set max reference frames that will be used to filter the encode, higher values would make the video blurrier at high fidelity but look better at lower bitrates.\\r\\n\\r\\n- `--butteraugli-resize-factor=2` if you use any of the butteraugli-based tunes (lavish, butteraugli) to speed it up without much losses and `--butteraugli-intensity-target=250` to match the content light level.\\r\\n\\r\\n\\r\\n## Final Thoughts\\r\\n\\r\\nEncoding has always been about experimentation for the best, there is really no \\"One size fits all\\" for encoding content, as they differ from scene complexity, how it\'s captured (2D/Real life), film grain, dark scenes, etc. So experiment away for your specific type of content!\\r\\n\\r\\n> **Guide originally hosted on https://rentry.co/AV1, rewrite and migration by Simulping.**"},{"id":"site-optimization","metadata":{"permalink":"/blog/site-optimization","source":"@site/blog/2023-07-21-site-optimization.mdx","title":"Reducing Image Load Online","description":"A big part of understanding any multimedia codec technology is knowing the application for such technology. For images, a big use case is web delivery.","date":"2023-07-21T00:00:00.000Z","formattedDate":"July 21, 2023","tags":[{"label":"image","permalink":"/blog/tags/image"},{"label":"web","permalink":"/blog/tags/web"},{"label":"compression","permalink":"/blog/tags/compression"}],"readingTime":9.25,"hasTruncateMarker":true,"authors":[{"name":"Gianni Rosato","title":"Maintainer","url":"https://github.com/gianni-rosato","image_url":"https://avatars.githubusercontent.com/u/35711760?v=4","imageURL":"https://avatars.githubusercontent.com/u/35711760?v=4"}],"frontMatter":{"title":"Reducing Image Load Online","description":"A big part of understanding any multimedia codec technology is knowing the application for such technology. For images, a big use case is web delivery.","slug":"site-optimization","authors":[{"name":"Gianni Rosato","title":"Maintainer","url":"https://github.com/gianni-rosato","image_url":"https://avatars.githubusercontent.com/u/35711760?v=4","imageURL":"https://avatars.githubusercontent.com/u/35711760?v=4"}],"tags":["image","web","compression"],"image":"/img/_DSC8466-smaller.jpg","hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"AV1 Encoding for Dummies","permalink":"/blog/av1-encoding-for-dummies"}},"content":"A big part of understanding any multimedia codec technology is knowing the application for such technology. For images, a big use case is web delivery. Compared to other multimedia, images are incredibly popular on the Web & knowing how to serve them properly can be a massive boon to your website\'s traffic as well as less of a headache for users on slower connections or who are under bandwidth constraints. The most disappointing part is that images are often poorly done on the web; all too frequently will you run into a site serving massive photographic PNGs for no reason, or photography sites serving photographs fresh out of the editing software with no thought put into their final delivery. A little effort, patience, & knowledge will go a long way toward improving the user experience for individuals using your site, & this article will illustrate some of the basics.\\r\\n\\r\\n\x3c!--truncate--\x3e\\r\\n\\r\\n:::caution\\r\\nThese instructions are for *photographic* images; other kinds of images, like non-photographic, artwork, pixel art, etc. should likely be handled differently.\\r\\n:::\\r\\n\\r\\n:::danger\\r\\nMany images won\'t load properly unless your browser supports JXL, AVIF, & proper ICCv2 color management. This is for demonstration purposes only & shouldn\'t represent an actual common website experience. If you\'re curious anyway, the following browsers can display the contents of this page perfectly:\\r\\n- [Thorium](https://thorium.rocks/) | *Linux, [macOS](https://github.com/Alex313031/Thorium-Special/releases), [Windows](https://github.com/Alex313031/thorium/releases/), [Android](https://github.com/Alex313031/Thorium-Special/releases)*\\r\\n- [Waterfox](https://www.waterfox.net/) | *[Linux](https://flathub.org/apps/net.waterfox.waterfox), [macOS](https://www.waterfox.net/download/), [Windows](https://www.waterfox.net/download/)*\\r\\n- [Mercury](https://thorium.rocks/mercury) | *[Linux](https://github.com/Alex313031/Mercury/releases), [Windows](https://github.com/Alex313031/Mercury/releases)*\\r\\n:::\\r\\n\\r\\n## Fire & Forget\\r\\n\\r\\nFirst, we\'ll illustrate what *not* to do, which is fortunately not incredibly difficult to avoid. Taking an image straight out of your editing software at a massive size will often bloat the size & resolution to something that isn\'t generally usable for a website regardless of the codec you\'re using & its quality per bit. It can be argued there are specific use cases that demand incredible resolution & fidelity coexist on the Web, but we won\'t be covering those here. Here\'s an example of a bloated image:\\r\\n\\r\\n*exported straight from Darktable at JPEG q90, with no scaling*\\r\\n\\r\\n![bloated_jpeg](/img/_DSC8466.jpg)\\r\\n\\r\\n**2.2 MB**\\r\\n\\r\\n## Massive Improvement\\r\\n\\r\\nThe easiest way to have a large improvement without doing much work is to simply resize the image before serving it. Even if you exported a lossy JPEG, resizing should remove a lot of artifacts. The way to perceive a worst-case for an image\'s size on a site is to inspect the image element\'s width & height, which should give us an estimate of how large we should make our image. Any larger than this value is unreasonable since we\'re overfilling the element\'s size for no reason & the image is being scaled down anyway.\\r\\n\\r\\n![box-size-mac](/img/box-size-mac.avif)\\r\\n*Inspect Element in Firefox. The Mac used to take this screenshot has a relatively high display resolution of 2560x1664. Because Macs scale things differently, we\'re probably going to want to double the horizontal resolution here.*\\r\\n\\r\\nThe width is the most important value here, so our new image is going to be exported with a width of 1699 pixels. This new image, encoded at JPEG q90 with `cjpegli`, looks like this:\\r\\n\\r\\n![smaller_jpeg](/img/_DSC8466-smaller.jpg)\\r\\n\\r\\nObviously, there\'s lost fidelity compared to the original, but considering this is *so much smaller*, it is worth the trade-off for many. It is also worth noting we are using an improved jpeg encoder in the form of `cjpegli`, although that is secondary to the resize. If it doesn\'t look as good as you want it to, you can always scale the resolution up a bit, though currently, it looks plenty passable for its size.\\r\\n\\r\\n2.2 MB -> **233 kB**\\r\\n\\r\\n### Lazy Loading\\r\\n\\r\\nA bonus tip is to add the `loading=\\"lazy\\"` attribute to your picture tag to allow the image to load only when scrolled to by a user. This doesn\'t save bandwidth, but it improves the user experience by loading images further down the page only when necessary. An example may look like this:\\r\\n\\r\\n```html\\r\\n<picture>\\r\\n    <img src=\\"/images/jpeg_fallback.jpg\\" alt=\\"alt text\\" width=\\"XX\\" height=\\"YY\\" loading=\\"lazy\\" />\\r\\n</picture> \\r\\n```\\r\\n\\r\\n## New Codecs\\r\\n\\r\\nIf you desire further improvement, it may be time to consider using a newer codec like [AVIF](https://wiki.x266.mov/docs/images/AVIF) or [JPEG-XL](https://wiki.x266.mov/docs/images/JXL). These options will compress far more effectively than JPEG, with the only trade-off being browser support. We\'re not going to consider [WebP](/docs/images/WebP) or [HEIC](/docs/images/HEIC), since WebP is not competitive enough with JPEG for photographic imagery (often being worse) & HEIC has been superseded by AVIF - which sees greater support anyhow - & is not royalty free, effectively preventing widespread Web adoption forever. Again, we\'re just considering *lossy* compression for *photographic* images; it is a different story with WebP elsewhere, as it performs well on non-photographic content & is almost always better than PNG for 8-bit lossless compression. So, we are left with JXL & AVIF for now.\\r\\n\\r\\n### Fallbacks\\r\\n\\r\\nAVIF sees widespread support, but JPEG-XL isn\'t quite there yet with Web support as Google continues to push AVIF (it is debatable if it ever will be outside the Apple ecosystem). Even with AVIF, adoption isn\'t remotely close to JPEG, so it is worth providing a fallback. This can look like the following example:\\r\\n\\r\\n```html\\r\\n<picture>\\r\\n    <source srcset=\\"/img/jxl_image.jxl\\" type=\\"image/jxl\\" />\\r\\n    <source srcset=\\"/img/avif_image.avif\\" type=\\"image/avif\\" />\\r\\n    <source srcset=\\"/img/webp_fback.webp\\" type=\\"image/webp\\" />\\r\\n    <img src=\\"/images/jpeg_fallback.jpg\\" alt=\\"alt text\\" width=\\"XX\\" height=\\"YY\\" loading=\\"lazy\\" />\\r\\n</picture> \\r\\n```\\r\\n\\r\\nHere is a JXL falling back to an AVIF falling back to a WebP falling back to a JPEG. Pretty intense to have this many fallbacks unless you\'re really after the ultimate compression ratio, but it is certainly an option. AVIF & JPEG alone will probably be enough for most.\\r\\n\\r\\n### Compression Efficacy\\r\\n\\r\\nLet\'s look at how our image examples compare to the original with our new codec selection. We\'ll be aiming for high visual fidelity, so around the same quality as our initial JPEG encoded with `cjpegli` (which scores ~`83.01` with the [SSIMULACRA2](/docs/metrics/SSIMULACRA2) visual fidelity metric).\\r\\n\\r\\n![smaller_jxl](/img/_DSC8466-smaller.jxl)\\r\\n\\r\\n**137.0 kB** *JPEG-XL image, encoded with `cjxl lossless.png out.jxl -d 1.49 -e 9`. Score: ~`83.04`* *3.06s user time*\\r\\n\\r\\n![smaller_avif](/img/_DSC8466-smaller.avif)\\r\\n\\r\\n**124.8 kB** *AVIF image, encoded with `avifenc -c aom -s 4 -j 8 -d 10 -y 444 --min 1 --max 63 -a end-usage=q -a cq-level=16 -a tune=ssim lossless.png out.avif`. Score: ~`83.03`* *7.54s user time*\\r\\n\\r\\nJXL also supports lossless transcoding of JPEG images. This means every pixel is identical, the image just has a smaller filesize than the original JPEG; if you can use JXL, you can transcode existing JPEGs losslessly on your site & save some bandwidth that way. The JPEG transcode below gives a higher SSIMULACRA2 score than the original for some reason, but I\'ll chalk that up to a decoding inconsistency between how the `ssimulacra2` program decodes JPEG & JXL. Either way, the scores are fairly close.\\r\\n\\r\\n![smaller_jxl_jpeg-recomp](/img/_DSC8466-smaller-recomp.jxl)\\r\\n\\r\\n**189.4 kB** *JPEG-XL image from JPEG, encoded with `cjxl input.jpg input-recomp.jxl -d 0.0 -e 9 --brotli_effort=11`. Score: ~`84.92` (???)* *0.67s user time*\\r\\n\\r\\nThe final trick we can use, while not a new codec at all, still increases quality per bit. Encoding an XYB JPEG with `cjpegli` encodes with the perceptual XYB colorspace using an ICC profile to modify the original JPEG colors, avoiding JPEG\'s normal YCbCr which isn\'t perceptually optimized for the human visual system. Using XYB, we can afford identical quality with less bitrate than normal JPEG. This has universal compatibility, but not every application understands how to handle the XYB color profile (although color-managed modern browsers should be fine).\\r\\n\\r\\n![smaller_jpeg_xyb](/img/_DSC8466-smaller-xyb.jpg)\\r\\n\\r\\n**208.3 kB** *XYB JPEG, encoded with `cjpegli lossless.png out.jpg --xyb -d 1.155`. Score: ~`83.04`* *0.10s user time*\\r\\n\\r\\nIn this particular instance, AVIF seems to be the overall winner. This isn\'t always the case due to JXL\'s superiority at higher fidelity & with more detailed images, but according to SSIMULACRA2, AVIF has the best quality per bit with this image. You can use your own eyes to further clarify your choice, though. It is worth mentioning that as these were encoded from a 16-bit source PNG, the JXL image is the only one that maintains the full original bit depth, & AVIF isn\'t fast to encode.\\r\\n\\r\\n## Responsive Images\\r\\n\\r\\nDisplaying an image that is too large for a viewport is a waste of bandwidth, & displaying an image that\'s too small for the viewport leaves fidelity to be desired. Luckily, we have the [Responsive Image Linter](https://ausi.github.io/respimagelint/) that can help us figure out which image sizes we should be using.\\r\\n\\r\\n![responsive_image_linter](/img/responsive_image_linter.avif)\\r\\n\\r\\nIn our fire & forget example, we see that we are serving an image that is far too large. We already know that, but now we can see that given various viewport sizes we could be serving images that have respective widths of 270px, 958px, 1350px, 1660px, & 1916px to optimize for delivery to a variety of different devices. Here\'s how we\'d write that in HTML:\\r\\n\\r\\n```html\\r\\n<picture>\\r\\n  <source type=\\"image/jxl\\" srcset=\\"/img_270.jxl 270w, /img_958.jxl 958w, /img_1350.jxl 1350w, /img_1660.jxl 1660w, /img_1916.jxl 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" />\\r\\n  <source type=\\"image/avif\\" srcset=\\"/img_270.avif 270w, /img_958.avif 958w, /img_1350.avif 1350w, /img_1660.avif 1660w, /img_1916.avif 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" />\\r\\n  <img width=\\"1699\\" height=\\"1136\\" alt=\\"alt text\\" srcset=\\"/img_270.jpg 270w, /img_958.jpg 958w, /img_1350.jpg 1350w, /img_1660.jpg 1660w, /img_1916.jpg 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" src=\\"/fallback.jpg\\" />\\r\\n</picture>\\r\\n```\\r\\n\\r\\nIt is worth noting that this example above & the example below aren\'t perfect implementations of a responsive image given the conditions of this site, but the general concept still applies. Some things to note:\\r\\n\\r\\n- `srcset` = the images available to your browser to serve, & their respective widths\\r\\n- `sizes` = the conditions given to the browser explaining under what conditions should it serve which image\\r\\n- `(min-width: XXXpx) YYYpx` = Given the viewport is at least XXX wide, serve an image of YYY horizontal resolution. The browser will pick an image from srcset that is CSS pixels \\\\* display scaling.\\r\\n- `calc(100vw - 24px)` = Usually preceded by a (min-width) condition. Specifies a value the browser should calculate on its own to pick the closest option from the srcset. Let\'s say we have `(min-width: 997px) calc(75vw - 257px)`. This means given the viewport is at least 997px wide, calculate 0.75 \\\\* the current viewport resolution - 257 to find the closest image in the srcset to fit the number of pixel specified.\\r\\n\\r\\n<picture>\\r\\n  <source type=\\"image/jxl\\" srcset=\\"https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_270.jxl 270w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_958.jxl 958w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1350.jxl 1350w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1660.jxl 1660w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1916.jxl 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" />\\r\\n  <source type=\\"image/avif\\" srcset=\\"https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_270.avif 270w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_958.avif 958w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1350.avif 1350w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1660.avif 1660w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1916.avif 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" />\\r\\n  <img loading=\\"lazy\\" width=\\"1699\\" alt=\\"alt text\\" srcset=\\"https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_270.jpg 270w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_958.jpg 958w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1350.jpg 1350w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1660.jpg 1660w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1916.jpg 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" src=\\"https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/_DSC8466-smaller.jpg\\" />\\r\\n</picture>\\r\\n\\r\\nThat\'s all! Massive thanks to Auto-Rez Media Technologies for the inspiration behind this article & explicit permission to use their [Reduce Your Page\'s Image Load](https://autocompressor.net/blog/reduce-image-load) blog post when writing this entry. I have [confirmed](https://autumn.revolt.chat/attachments/GtFGuwNfeRdcwUN0MWzhDCAiiadWOk88XXC3pQv6RI) with their leadership that this wiki entry can be safely licensed under CC BY-SA 4.0."}]}')}}]);