"use strict";(self.webpackChunkcodec_wiki=self.webpackChunkcodec_wiki||[]).push([[1477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"av1-encoding-for-dummies","metadata":{"permalink":"/blog/av1-encoding-for-dummies","source":"@site/blog/2023-09-03-av1-for-dummies.md","title":"AV1 Encoding for Dummies","description":"AV1 Encoding for Dummies","date":"2023-09-03T00:00:00.000Z","formattedDate":"September 3, 2023","tags":[{"label":"video","permalink":"/blog/tags/video"},{"label":"compression","permalink":"/blog/tags/compression"}],"readingTime":15.145,"hasTruncateMarker":true,"authors":[{"name":"Simulping","title":"Maintainer / Encoder","url":"https://github.com/Simulping","image_url":"https://avatars.githubusercontent.com/u/12994794?v=4","imageURL":"https://avatars.githubusercontent.com/u/12994794?v=4"},{"name":"Gianni Rosato","title":"Maintainer","url":"https://github.com/gianni-rosato","image_url":"https://avatars.githubusercontent.com/u/35711760?v=4","imageURL":"https://avatars.githubusercontent.com/u/35711760?v=4"}],"frontMatter":{"title":"AV1 Encoding for Dummies","description":"AV1 Encoding for Dummies","slug":"av1-encoding-for-dummies","authors":[{"name":"Simulping","title":"Maintainer / Encoder","url":"https://github.com/Simulping","image_url":"https://avatars.githubusercontent.com/u/12994794?v=4","imageURL":"https://avatars.githubusercontent.com/u/12994794?v=4"},{"name":"Gianni Rosato","title":"Maintainer","url":"https://github.com/gianni-rosato","image_url":"https://avatars.githubusercontent.com/u/35711760?v=4","imageURL":"https://avatars.githubusercontent.com/u/35711760?v=4"}],"tags":["video","compression"],"hide_table_of_contents":false},"nextItem":{"title":"Site Optimization by Reducing Image Load on the Web","permalink":"/blog/site-optimization"}},"content":"This guide will show you how to encode in AV1 the *right* and *optimal* way. Yes, you using standalone ``libaom``, ``libsvtav1``, and ``librav1e`` from FFmpeg or even piping ``yuv4mpeg`` into **mainline** aomenc are all unoptimal.\\n\\n\x3c!--truncate--\x3e\\n\\n\\n![Compare](/img/compare-guide.webp)\\n\\nIn this guide, we\'ll be installing Av1an for chunked encoding and infinite threading, because the current state of AV1 encoders, except for [SVT-AV1](https://wiki.x266.mov/docs/encoders/SVT-AV1), unfortunately lacks threading and will only use very low amount of cores, which hampers speeds. The only caveat to this approach is **RAM consumption**, encoding 2160p (4K) with [aomenc](https://wiki.x266.mov/docs/encoders/aomenc) with 4 workers could take upwards of **16GB** of RAM! So do keep this in mind.\\n\\n## Installing the Tools\\n\\n### Microsoft Windows\\n\\n**The GUI Way:**\\n1. Install [NMKODER](https://github.com/n00mkrad/nmkoder) which is a GUI front-end to av1an with all dependencies installed.\\n2. You\'re done, you can skip to the encoding part\\n\\n:::warning Almost abandonware\\nSince Nmkoder already ships everything by default and its last release was 29th March 2022. You need to manually update all encoders and tools to get better encoding speeds. Missing out on updates will result in your encodes being sub-optimal.\\n:::\\n\\n**The Automated Way:**\\n\\nThere is now a batch script for automating the install process, which can be found [here](https://github.com/Hishiro64/av1an-win-script). The instructions are in the README file.\\n\\n:::caution\\nThe script will download outdated version encoders and tools such as `aom-av1-psy` and MKVToolNix v76.0, if you are fine with these you can proceed.\\n:::\\n\\n**The Manual Way:**\\n1. Install **Python 3.10.x, this will change so consult from the** [Vapoursynth website](http://www.vapoursynth.com/doc/installation.html) **if you\'re reading this from the future** from [here](https://www.python.org/downloads/windows/) and select \\"Windows Installer 64-bit\\". Upon installation check the tick for adding Python to PATH like so\\n![Python PATH](/img/python-path.webp))\\n\\n2. Download and install Vapoursynth from [here](https://github.com/vapoursynth/vapoursynth/releases) and select \\"VapourSynth64-RXX.exe\\"\\n3. Open the terminal and type ``vsrepo.py install lsmas ffms2`` to install some plugins for Av1an to work.\\n4. Download MKVToolNix from [here](https://mkvtoolnix.download/downloads.html#windows), select \\"mkvtoolnix-64bit-XX.X.X-setup.exe\\", and install **(Also available on winget!)**\\n5. Download Av1an from [here](https://github.com/master-of-zen/Av1an/releases) (SELECT LATEST AND CLICK THE \\"ASSETS\\" DROPDOWN)\\n6. Download **shared libraries** FFmpeg from [gyan.dev](https://www.gyan.dev/ffmpeg/builds)\\n7. Download a pre-built fork of Aomenc ([aom-av1-lavish](https://github.com/Clybius/aom-av1-lavish/tree/Endless_Merging)) which has neat stuff such as sane defaults, new tunes, optimizations, etc. This can be downloaded for Windows [here](https://autumn.revolt.chat/attachments/download/-2EiZW1edcT9anApFZ1PJBEber-pJ6z02NiQBjbr28) *(Current as of Sept 6, 2023)*\\n:::info\\nIf you opt to compile aomenc yourself, you can view the instructions on how to do that [here](https://wiki.x266.mov/docs/encoders/aomenc/#installation).\\n:::\\n8. Move Av1an, FFmpeg **(Including the FFmpeg DLLs)**, and aomenc to somewhere preferable, eg ``C:\\\\Encoding``.\\n9. Add the folder **AND MKVTOOLNIX INSTALLATION FOLDER** to the [Windows PATH environment](https://www.maketecheasier.com/what-is-the-windows-path/).\\n\\n\\n### macOS\\n*written by gb82 (Gianni Rosato)*\\n\\nmacOS is very similar to Linux, although there aren\'t any GUI tools for AV1 encoding that I can comfortably recommend.\\n\\n**Homebrew + Macports for Av1an + rav1e:**\\n*Note that some commands may have to be run with `sudo`, which I won\'t explicitly include for security reasons.*\\n\\nInstalling the Homebrew package manager is a well documented process at this point:\\n```bash\\n/bin/bash -c \\"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\\"\\n```\\n\\nAs is installing MacPorts. Install the relevent `.pkg` for your macOS version from the MacPorts Project website:\\n[www.macports.org/install.php](https://www.macports.org/install.php)\\n\\nNow, you can run the following commands:\\n```bash\\nbrew update && brew upgrade\\nbrew install rav1e aom mkvtoolnix ffmpeg\\n# Usually you must run MacPorts commands for package installations as root\\nport upgrade outdated\\nport install av1an\\n```\\n\\nThis is the easiest way to get everything set up & working to produce AV1 video with `rav1e` or mainline `aomenc` & Av1an. You can check that things are installed by running the following commands & parsing their output:\\n```bash\\n% av1an --version\\nav1an 0.4.1-unstable (rev e10880d) (Release)\\n\\n* Compiler\\n  rustc 1.70.0 (LLVM 16.0)\\n\\n* Target Triple\\n  aarch64-apple-darwin\\n\\n* Date Info\\n  Commit Date:  2023-06-25\\n\\n* VapourSynth Plugins\\n  systems.innocent.lsmas : Not found\\n  com.vapoursynth.ffms2  : Not found\\n```\\n```bash\\n% rav1e --version | grep \\"release\\" -C 1      \\nrav1e 0.6.6 () (release)\\nrustc 1.69.0 (84c898d65 2023-04-16) (built from a source tarball) aarch64-apple-darwin\\n```\\n```bash\\n% aomenc --help | grep \\"AOMedia\\" -C 3\\n\\nIncluded encoders:\\n\\n    av1    - AOMedia Project AV1 Encoder 3.6.1 (default)\\n\\n        Use --codec to switch to a non-default encoder.\\n```\\n\\nNotice `systems.innocent.lsmas : Not found` in the Av1an output. This means you won\'t be able to use the lsmash chunking method through vapoursynth & may instead have to rely on hybrid chunking, through `-m hybrid`. This is slower & takes up disk space while encoding, but still works. A sample Av1an command with this basic installation may look like this:\\n\\n```bash\\nav1an -i \\"input\\" -y --resume --verbose --split-method av-scenechange -m hybrid -c mkvmerge -e rav1e --force -v \\" --tiles 8 -s 4 --quantizer 80 --no-scene-detection\\" --photon-noise 7 --chroma-noise --pix-format yuv420p10le -w 8 -o \\"output.mkv\\"\\n```\\n\\n**Building From Source**\\n\\nIf you want lsmash support, aom-av1-lavish instead of mainline, or anything else that isn\'t covered by the more basic installation, you\'ll have to compile from source. Things are very similar to Linux, with a few oddities:\\n\\n- macOS sometimes doesn\'t have a `/usr/local/bin` by default. You can fix this by doing `mkdir /usr/local/bin`.\\n- Homebrew installs *everything* in its own directory structure. If you\'re building things from source that rely on libraries from vapoursynth, zimg, lsmash, etc, make sure to copy them from `/opt/homebrew/lib` to `/usr/local/lib`. Finding them is a matter of `ls | grep \\"keyword\\"` & copying what looks reasonable to be associated with the tool you\'re using.\\n- Building most things from source will have instructions for \\\\*nix which work for both macOS & Linux. Even if it says Linux, there\'s a good chance it\'ll work on macOS as well, & it is always worth trying Linux build instructions on Mac. I won\'t be going through building every encoding tool & dependency from source, as it is generally much more intuitive than Windows, but building Av1an is worth detailing here just as an example.\\n```bash\\nbrew install git rust nasm\\ngit clone https://github.com/master-of-zen/Av1an\\ncd Av1an\\nRUSTFLAGS=\\"-C target-cpu=native\\" cargo build --release\\ncd .. && cd target/release\\ncp av1an /usr/local/bin\\n```\\n\\n**More Difficult: Building aom-av1-lavish from Source**\\n\\nIf you want to make the most out of your hardware & eke out every last drop of quality, it may be worth building aom-av1-lavish from source. The first step is to clone it from the Endless Merging branch:\\n```bash\\ngit clone https://github.com/Clybius/aom-av1-lavish -b Endless_Merging\\ncd aom-av1-lavish\\n```\\nNow, you need to make some manual changes to the source code until Clybius merges [this commit](https://github.com/Clybius/aom-av1-lavish/pull/1/files).\\n- Add the line `#include \\"aq_variance.h\\"` at line 19 in `av1/encoder/encodeframe_utils.c`\\n- Comment out line 2546 in `av1/encoder/speed_features.c`. This line is `const int qindex_thresh_cdef_sf_s1_s3_l2[2] = { 92, 48 };` & becomes `// const int qindex_thresh_cdef_sf_s1_s3_l2[2] = { 92, 48 };`.\\n\\nNow you can continue to build according to the Linux instructions below. Obviously you\'ll need cmake, which you can install with homebrew along with any other tools you may need. While still in the `aom-av1-lavish` directory:\\n```bash\\nmkdir -p aom_build && cd aom_build\\ncmake .. -DBUILD_SHARED_LIBS=0 -DENABLE_DOCS=0 -DCONFIG_TUNE_BUTTERAUGLI=0 -DCONFIG_TUNE_VMAF=0 -DCONFIG_AV1_DECODER=0 -DENABLE_TESTS=0 -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=\\"-flto -O3 -march=native\\" -DCMAKE_C_FLAGS=\\"-flto -O3 -march=native -pipe -fno-plt\\" -DCMAKE_LD_FLAGS=\\"-flto -O3 -march=native\\"\\nmake -j$(nproc)\\n# This may need to be run as root:\\nmake install\\n```\\n\\nNow you can run `aomenc --help | grep \\"AOMedia\\" -C 3` to see if lavish installed. If you\'re getting the same output as above, you may need to copy the `aomenc` executable to `/opt/local/bin`, `/usr/local/bin`, & `/opt/homebrew/bin` if you already installed mainline aomenc. Running the version info command again, the correct output should look something like this:\\n```bash\\n% aomenc --help | grep AOMedia -C 3\\n\\nIncluded encoders:\\n\\n    av1    - AOMedia Project AV1 Encoder Psy v3.6.0 (default)\\n\\n        Use --codec to switch to a non-default encoder.\\n```\\n\\nNotice how it says `AOMedia Project AV1 Encoder Psy` instead of `AOMedia Project AV1 Encoder`. You should be all set after this to start using aom-av1-lavish & following the current parameter meta as outlined below.\\n\\n### Linux\\n\\n:::info\\nYet again, try using Arch. It\'s way easier.\\n:::\\n\\n#### The Easy Ways\\n\\n- Install [Aviator](https://github.com/gianni-rosato/aviator) ([SVT-AV1](https://wiki.x266.mov/docs/encoders/SVT-AV1) + [FFmpeg](https://wiki.x266.mov/docs/utilities/FFmpeg)) or [rAV1ator](https://giannirosato.com/blog/post/aviator-1/) basically same thing but [Av1an](https://wiki.x266.mov/docs/utilities/av1an.md) + [rav1e](https://wiki.x266.mov/docs/encoders/rav1e). Both are only available as [Flatpaks](https://beta.flathub.org/apps/net.natesales.Aviator). Keep in mind Aviator ships with **SVT-AV1** and rAV1ator with **rav1e** instead of aomenc/AOM-AV1, which I will not be covering here.\\n- Install [rav1ator-cli](https://wiki.x266.mov/docs/utilities/rav1ator-cli), a TUI for using Av1an meant to be easy to use. Much more flexible than the GUI options & can work with a number of encoders. See [this page](https://wiki.x266.mov/docs/utilities/rav1ator-cli/#installation) for more info.\\n\\n#### The Compiling Route\\n\\n##### Ubuntu\\n\\nThe guide below is targeted towards 22.04, packages and other things may be different on other versions. First Install Rust via `rustup` first, as apt version of Rust is severely outdated, then you can continue.\\n\\nInstall dependencies:\\n```bash\\nsudo apt install wget python unzip unrar build-essential meson autoconf automake libtool git nasm yasm python3-dev python3-pip cython3 libass-dev libqt5websockets5-dev libfftw3-dev libtesseract-dev ffmpeg libavcodec-dev libavformat-dev libswscale-dev libavutil-dev libswresample-dev libmediainfo-dev mkvtoolnix mediainfo perl nasm yasm git cmake libavutil-dev libavcodec-dev libavformat-dev libavdevice-dev libavfilter-dev libswscale-dev libswresample-dev libpostproc-dev llvm libclang-dev libssl-dev\\n```\\n\\nInstall l-smash:\\n```bash\\ngit clone https://github.com/l-smash/l-smash.git\\ncd l-smash\\n./configure --enable-shared --extra-cflags=\\"-march=native\\"\\nmake -j$(nproc)\\nsudo make install\\n```\\n\\nInstall zimg:\\n```bash\\ngit clone --recursive https://github.com/sekrit-twc/zimg.git\\ncd zimg\\n./autogen.sh\\n./configure\\nmake -j$(nproc)\\nsudo make install\\n```\\n\\nInstall ImageMagick:\\n```bash\\ngit clone https://github.com/ImageMagick/ImageMagick\\ncd ImageMagick\\n./configure\\nmake -j$(nproc)\\nsudo make install\\n```\\n\\nInstall Vapoursynth R63:\\n```bash\\nwget https://github.com/vapoursynth/vapoursynth/archive/refs/tags/R63.zip\\nunzip R63.zip\\ncd vapoursynth-R63\\n./autogen.sh\\n./configure CFLAGS=\\"-march=native\\" CXXFLAGS=\\"-march=native\\" --libdir=/usr/lib\\nmake -j$(nproc)\\nsudo make install\\nsudo mkdir /usr/lib/vapoursynth\\nsudo ldconfig\\n```\\nThe plugin directory will be located in `/usr/lib/vapoursynth`.\\n\\n\\nInstall L-SMASH-Works Vapoursynth Plugin:\\n```bash\\ngit clone https://github.com/AkarinVS/L-SMASH-Works -b ffmpeg-4.5\\ncd L-SMASH-Works/VapourSynth && mkdir build && cd build\\nmeson .. --optimization=3 --default-library=static -Db_lto=true -Dc_args=\\"-march=native\\" -Dcpp_args=\\"-march=native\\"\\nninja -j$(nproc)\\nsudo cp libvslsmashsource.so /usr/lib/vapoursynth/\\n```\\n\\n:::caution\\nL-SMASH-Works doesn\'t work on **aarch64**, it is recommended to use other plugins instead.\\n:::\\n\\nInstall FFMS2 Vapoursynth Plugin:\\n```bash\\ngit clone https://github.com/FFMS/ffms2\\ncd ffms2\\n./autogen.sh\\n./configure CFLAGS=\\"-O3 -march=native\\" CXXFLAGS=\\"-O3 -march=native\\"\\nmake -j$(nproc)\\nsudo cp src/core/.libs/libffms2.so src/core/.libs/libffms2.so.5 src/core/.libs/libffms2.so.5.0.0 /usr/lib/vapoursynth\\n```\\n\\nInstall Av1an:\\n```bash\\ngit clone https://github.com/master-of-zen/Av1an\\ncd Av1an\\nRUSTFLAGS=\\"-C target-cpu=native\\" cargo build --release\\nsudo cp target/release/av1an /usr/local/bin\\n```\\n\\nWhen there\'s no errors, proceed to compiling `aom-av1-lavish`.\\n\\n##### Arch\\n\\nInstall dependencies:\\n```bash\\nsudo pacman -S vapoursynth ffmpeg av1an mkvtoolnix-gui git perl cmake ninja meson nasm vapoursynth-plugin-lsmashsource ffms2\\n```\\n\\nyou\'re done, proceed.\\n\\n#### Compiling aom-av1-lavish\\n``` bash\\ngit clone https://github.com/Clybius/aom-av1-lavish -b Endless_Merging\\ncd aom-av1-lavish && mkdir -p aom_build && cd aom_build\\ncmake .. -DBUILD_SHARED_LIBS=0 -DENABLE_DOCS=0 -DCONFIG_TUNE_BUTTERAUGLI=0 -DCONFIG_TUNE_VMAF=0 -DCONFIG_AV1_DECODER=0 -DENABLE_TESTS=0 -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=\\"-flto -O3 -march=native\\" -DCMAKE_C_FLAGS=\\"-flto -O3 -march=native -pipe -fno-plt\\"\\nmake -j$(nproc)\\nsudo make install\\n```\\n\\n## Encoding\\n\\nThe moment you\'ve all been waiting for, let\'s just get into it. Here\'s an example *recommended* parameter as of now (09/03/23) [MM/DD/YY]:\\n```bash\\nav1an -x 300 -i input.mkv -w 4 -e aom -c mkvmerge --resume -m lsmash --photon-noise=10 --set-thread-affinity=2 --verbose -a \\" -an \\" -f \\" -an \\" -v \\" --bit-depth=10 --cpu-used=4 --end-usage=q --cq-level=24 --threads=2 --tile-columns=0 --tile-rows=0 --lag-in-frames=64 --tune-content=psy --tune=ssim --enable-keyframe-filtering=1 --disable-kf --kf-max-dist=9999 --enable-qm=1 --deltaq-mode=0 --aq-mode=0 --quant-b-adapt=1 --enable-fwd-kf=0 --arnr-strength=1 --sb-size=dynamic --enable-dnl-denoising=0 \\" -o \\"output.mkv\\"\\n```\\n\\n:::info Parameter Meta\\nIt is strongly recommended to join the [AV1 Discord server](https://discord.gg/vpREHAvYvh) to get the latest updates on what to use and which to set, as it\'s the only easily reachable place for everything AV1 & encoding tips in general.\\n:::\\nNow let\'s dissect it one-by-one\\n\\n**Av1an parameters:**\\n\\n- ``-i`` Input.\\n\\n- ``-x 300`` Sets scene split length to 300 frames, you can increase it for more quality at the tradeoff of video seekability.\\n\\n- ``-w 4`` Specifies the amount of \\"workers\\" or amount of encoders working on the video.\\n\\n- ``--verbose`` Sets logging to verbose.\\n\\n- ``--resume`` Resumes the encode even when you haven\'t encoded yet. I strongly recommend leaving this if you resume a lot since you can accidentally delete your whole progress (There\'s no delete confirmation feature.. yet) if you \\"resumed\\" without the parameter in place.\\n\\n- ``-e aom`` Specifies we\'re using aomenc encoder which should be the default option.\\n\\n- ``-c mkvmerge`` Specifies we\'re using mkvmerge (MKVToolNix) to concatenate the parts when done, you can specify with ffmpeg if you want to but this is the best method.\\n\\n- ``-m lsmash`` Specifies we\'re using l-smash (Vapoursynth plugin) to split the videos, this is also the best method because ffms2 causes video lag (Tested a year ago, might change now) and other methods just suck (Slow and not worth it, learned the hard way). You can attempt to use ffms2 when inputting VC-1 videos as it is not possible with l-smash (Or convert it to lossless with x264 qp 0).\\n\\n- ``-f \\" -an \\"`` ``-f`` Stands for ffmpeg parameters, ``-an`` is to remove all audio since its better to encode and merge it separately. To crop use ``-f \\" -an -vf crop=1920:800 \\"`` for example to crop the video to 1920x800.\\n\\n- ``-v \\" \\"`` Is where you put the encoder\'s parameters in.\\n\\n- ``-a \\" -an \\"`` FFmpeg audio encoding options, we\'re removing it cause we can always add it later. But if you want to, you can also encode directly. Here\'s an example for encoding to Opus using libopus assuming stereo: `-a \\" -c:a libopus -b:a 128k \\"`.\\n\\n- ``--photon-noise=10`` AV1 grain synthesis, which is a technique where the encoder puts fake grain in so it looks more natural and potentially hiding video artifacts (cause grain is hard to encode and explodes bitrate usage because of their randomness), 5-8 for almost none to little grain, 10-14 for medium, 15+ heavy, 20+ extremely heavy, 30+ for extremely grainy 90s live action films.\\n\\n- ``--set-thread-affinity=2`` Pins the thread to the encoder, aligns with ``--threads=2`` in the encoder parameter so set them accordingly.\\n\\n\\n**aomenc parameters:**\\n- ``--bit-depth=10`` We\'re using 10bit because it makes the video smaller and reduces [banding](https://developer.mozilla.org/en-US/docs/Web/Media/Formats/Video_codecs#contouring).\\n\\n- ``--cpu-used=4`` This is the preset which ranges from 0-9, you can go to 3 if you want more efficiency, 2 if you have a lot of time, 4 is the sweet spot, and 6 if you want speed. Don\'t go above 6 (Worst efficiency) or even 0 (It would take WEEKS to finish).\\n\\n- ``--end-usage=q --cq-level=24`` This specifies that we are going to use a knockoff version of CRF level similar to x264/x265 encoders, in this case CRF 24.\\n\\n- `--threads=2` Sets the amount of threads the encoder can use, aligns with `--set-thread-affinity` in Av1an.\\n\\n- ``--tile-columns=0 --tile-rows=0`` This is the tiles options, where the encoder splits the videos into tiles to encode faster, see the image below (Yellow lines):\\n<picture>\\n    <source srcset=\\"https://raw.githubusercontent.com/av1-community-contributors/images/main/tiling_av1.avif?token=GHSAT0AAAAAACEZPDXIZARY5MGSTJW4SI22ZHY636A\\" type=\\"image/avif\\" />\\n    <img src=\\"https://autumn.revolt.chat/attachments/HwhZjoDsdzLZsJM2mjzX7lEDmJn1xcYNdrQqmOxPYW/tiling_av1.jpeg\\" alt=\\"Tiling\\" width=\\"1280\\" height=\\"768\\" loading=\\"lazy\\" />\\n</picture> \\n\\n:::note Tile usage\\nDo NOT use tiles for 1080p and below, use 1 ``tile-columns`` at 1440p (2K), 2 ``tile-columns`` and 1 ``tile-rows`` for 2160p (4K)\\n:::\\n\\n- ``--lag-in-frames=64`` Knockoff of x264/x265 [Group of Pictures](https://en.wikipedia.org/wiki/Group_of_pictures) (GOP), makes the encoder look into future frames for better compression decision making, do not go over 64 as it is pretty much useless.\\n \\n- ``--aq-mode`` adaptive quantization mode, 0 is better most of the time\\n\\n- ``--tune-content=psy --tune=ssim`` As the name suggests they are tunes that affect the video output, for the better, and for the worst\\n\\n:::info Tunes to use\\nSet ``tune-content`` to ``animation`` if you\'re encoding above ``cq-level=30`` A.K.A lower quality, despite it\'s name\\nSet ``tune-content`` to ``psy`` for everything else, **do not use if you encode above ``cq-level=30``**\\nFor ``tune``, this is a bit tricky. For now, the meta seems to be ``ssim``, but back then it was ``lavish`` which is considered THE best tune because it\'s based on [butteraugli](https://github.com/google/butteraugli). Now it\'s fallen behind because its more blurry than ``ssim``, and before that it was ``butteraugli``, and then ``ipq_vmaf_psy``, and finally just ``ipq``. \\nIf you use any of the VMAF tunes, **you need to specify ``--vmaf-model-path=`` to where you put it**.\\n:::\\n\\n- ``--enable-keyframe-filtering=1`` We\'re setting it to 1 because of compatibility reasons, 2 is more efficient but there are seeking issues and FFmpeg for some reason can\'t input it.\\n\\n- ``--sb-size=dynamic`` Allows the encoder to use 128x128 block partitioning besides 64x64 which gives an efficiency boost, ignore it.\\n\\n- ``--deltaq-mode`` set to 0 because its just better.\\n\\n- ``--arnr-strength=1`` Controls how strong the filtering will be, 1 is good for 3D Pixar CGI-like and 2D animation, use 4 if you\'re doing live action content. Using maximum at higher bitrates would just result in a blurry mess.\\n\\n- ``--disable-kf --enable-fwd-kf=0`` We\'re disabling keyframes cause **Av1an already did scene detection, so we wont have to.**. And it speeds things up.\\n\\n- ``--kf-max-dist=9999`` Maximum keyframe interval, we\'re setting it at the highest possible value since av1an\'s scene detection keyframe interval is already 240 by default\\n\\n- ``--enable-chroma-deltaq=1 --enable-qm=1 --quant-b-adapt=1`` Parameters that give you free efficiency boost.\\n\\n- ``--enable-dnl-denoising=0`` Disables the encoder\'s built-in denoising technique when grain synthesis is enabled, you can optionally set it to 1 when you have a pretty noisy video since it works quite well.\\n\\n\\n:::info Concatenation Error on Linux\\nRun ``ulimit -n 200000``, resume, and it should concatenate just fine. If it still errors, head to the encode directory > encode, and run ``mkvmerge @../options.json``\\n:::\\n\\n\\n## Merging Everything\\n\\nOnce you\'re done just encode your audio using ffmpeg (or just passthrough it), subtitles should be carried along with your video output, and merge them in MKVToolNix! Don\'t want Matroska files? That\'s fine, you can use FFmpeg or MP4Box to output into `mp4`, just keep in mind that PGS/SUP/VOBSUB subtitles are not supported and Opus audio support is still experimental.\\n\\n\\n## Tips & Tricks\\n\\n- `--denoise-noise-level=10` Alternative to `photon-noise`, slower than photon-noise and is the OG grain synthesis method, performs okay and just serves as an alternative. Don\'t attempt to use it at high values (>12) since it creates noticeable grain patterns.\\n\\n- `--arnr-maxframes` to set max reference frames that will be used to filter the encode, higher values would make the video blurrier at high fidelity but look better at lower bitrates.\\n\\n- `--butteraugli-resize-factor=2` if you use any of the butteraugli-based tunes (lavish, butteraugli) to speed it up without much losses and `--butteraugli-intensity-target=250` to match the content light level.\\n\\n\\n## Final Thoughts\\n\\nEncoding has always been about experimentation for the best, there is really no \\"One size fits all\\" for encoding content, as they differ from scene complexity, how it\'s captured (2D/Real life), film grain, dark scenes, etc. So experiment away for your specific type of content!\\n\\n> **Guide originally hosted on https://rentry.co/AV1, rewrite and migration by Simulping.**"},{"id":"site-optimization","metadata":{"permalink":"/blog/site-optimization","source":"@site/blog/2023-07-21-site-optimization.md","title":"Site Optimization by Reducing Image Load on the Web","description":"Site Optimization by Reducing Image Load on the Web","date":"2023-07-21T00:00:00.000Z","formattedDate":"July 21, 2023","tags":[{"label":"image","permalink":"/blog/tags/image"},{"label":"web","permalink":"/blog/tags/web"},{"label":"compression","permalink":"/blog/tags/compression"}],"readingTime":9.255,"hasTruncateMarker":true,"authors":[{"name":"RootAtKali","title":"Autocompressor Founder / CEO","image_url":"https://cdn.discordapp.com/avatars/456553041902960660/e57850912e0cd8dd62cb20439e0b36ea.jpg","imageURL":"https://cdn.discordapp.com/avatars/456553041902960660/e57850912e0cd8dd62cb20439e0b36ea.jpg"},{"name":"Gianni Rosato","title":"Maintainer","url":"https://github.com/gianni-rosato","image_url":"https://avatars.githubusercontent.com/u/35711760?v=4","imageURL":"https://avatars.githubusercontent.com/u/35711760?v=4"}],"frontMatter":{"title":"Site Optimization by Reducing Image Load on the Web","description":"Site Optimization by Reducing Image Load on the Web","slug":"site-optimization","authors":[{"name":"RootAtKali","title":"Autocompressor Founder / CEO","image_url":"https://cdn.discordapp.com/avatars/456553041902960660/e57850912e0cd8dd62cb20439e0b36ea.jpg","imageURL":"https://cdn.discordapp.com/avatars/456553041902960660/e57850912e0cd8dd62cb20439e0b36ea.jpg"},{"name":"Gianni Rosato","title":"Maintainer","url":"https://github.com/gianni-rosato","image_url":"https://avatars.githubusercontent.com/u/35711760?v=4","imageURL":"https://avatars.githubusercontent.com/u/35711760?v=4"}],"tags":["image","web","compression"],"hide_table_of_contents":false},"prevItem":{"title":"AV1 Encoding for Dummies","permalink":"/blog/av1-encoding-for-dummies"}},"content":"A big part of understanding any multimedia codec technology is knowing the application for such technology.\\n\\n\x3c!--truncate--\x3e\\n\\n\\nFor images, a big use case is web delivery. Compared to other multimedia, images are incredibly popular on the Web & knowing how to serve them properly can be a massive boon to your website\'s traffic as well as less of a headache for users on slower connections or who are under bandwidth constraints. The most disappointing part is that images are often poorly done on the web; all too frequently will you run into a site serving massive photographic PNGs for no reason, or photography sites serving photographs fresh out of the editing software with no thought put into their final delivery. A little effort, patience, & knowledge will go a long way toward improving the user experience for individuals using your site, & this article will illustrate some of the basics.\\n\\n:::caution\\nThese instructions are for *photographic* images; other kinds of images, like non-photographic, artwork, pixel art, etc. should likely be handled differently.\\n:::\\n\\n:::warning\\nMany images won\'t load properly unless your browser supports JXL, AVIF, & proper ICCv2 color management. This is for demonstration purposes only & shouldn\'t represent an actual common website experience. If you\'re curious anyway, the following browsers can display the contents of this page perfectly:\\n- [Thorium](https://thorium.rocks/) | *Linux, [macOS](https://github.com/Alex313031/Thorium-Special/releases), [Windows](https://github.com/Alex313031/thorium/releases/), [Android](https://github.com/Alex313031/Thorium-Special/releases)*\\n- [Waterfox](https://www.waterfox.net/) | *[Linux](https://flathub.org/apps/net.waterfox.waterfox), [macOS](https://www.waterfox.net/download/), [Windows](https://www.waterfox.net/download/)*\\n- [Mercury](https://thorium.rocks/mercury) | *[Linux](https://github.com/Alex313031/Mercury/releases), [Windows](https://github.com/Alex313031/Mercury/releases)*\\n:::\\n\\n## Fire & Forget\\n\\nFirst, we\'ll illustrate what *not* to do, which is fortunately not incredibly difficult to avoid. Taking an image straight out of your editing software at a massive size will often bloat the size & resolution to something that isn\'t generally usable for a website regardless of the codec you\'re using & its quality per bit. It can be argued there are specific use cases that demand incredible resolution & fidelity coexist on the Web, but we won\'t be covering those here. Here\'s an example of a bloated image:\\n\\n*exported straight from Darktable at JPEG q90, with no scaling*\\n\\n![bloated_jpeg](/img/_DSC8466.jpg)\\n\\n**2.2 MB**\\n\\n## Massive Improvement\\n\\nThe easiest way to have a large improvement without doing much work is to simply resize the image before serving it. Even if you exported a lossy JPEG, resizing should remove a lot of artifacts. The way to perceive a worst-case for an image\'s size on a site is to inspect the image element\'s width & height, which should give us an estimate of how large we should make our image. Any larger than this value is unreasonable since we\'re overfilling the element\'s size for no reason & the image is being scaled down anyway.\\n\\n![box-size-mac](/img/box-size-mac.avif)\\n*Inspect Element in Firefox. The Mac used to take this screenshot has a relatively high display resolution of 2560x1664. Because Macs scale things differently, we\'re probably going to want to double the horizontal resolution here.*\\n\\nThe width is the most important value here, so our new image is going to be exported with a width of 1699 pixels. This new image, encoded at JPEG q90 with `cjpegli`, looks like this:\\n\\n![smaller_jpeg](/img/_DSC8466-smaller.jpg)\\n\\nObviously, there\'s lost fidelity compared to the original, but considering this is *so much smaller*, it is worth the trade-off for many. It is also worth noting we are using an improved jpeg encoder in the form of `cjpegli`, although that is secondary to the resize. If it doesn\'t look as good as you want it to, you can always scale the resolution up a bit, though currently, it looks plenty passable for its size.\\n\\n2.2 MB -> **233 kB**\\n\\n### Lazy Loading\\n\\nA bonus tip is to add the `loading=\\"lazy\\"` attribute to your picture tag to allow the image to load only when scrolled to by a user. This doesn\'t save bandwidth, but it improves the user experience by loading images further down the page only when necessary. An example may look like this:\\n\\n```html\\n<picture>\\n    <img src=\\"/images/jpeg_fallback.jpg\\" alt=\\"alt text\\" width=\\"XX\\" height=\\"YY\\" loading=\\"lazy\\" />\\n</picture> \\n```\\n\\n## New Codecs\\n\\nIf you desire further improvement, it may be time to consider using a newer codec like [AVIF](/docs/images/AVIF) or [JPEG-XL](/docs/images/JXL). These options will compress far more effectively than JPEG, with the only trade-off being browser support. We\'re not going to consider [WebP](/docs/images/WebP) or [HEIC](/docs/images/HEIC), since WebP is not competitive enough with JPEG for photographic imagery (often being worse) & HEIC has been superseded by AVIF - which sees greater support anyhow - & is not royalty free, effectively preventing widespread Web adoption forever. Again, we\'re just considering *lossy* compression for *photographic* images; it is a different story with WebP elsewhere, as it performs well on non-photographic content & is almost always better than PNG for 8-bit lossless compression. So, we are left with JXL & AVIF for now.\\n\\n### Fallbacks\\n\\nAVIF sees widespread support, but JPEG-XL isn\'t quite there yet with Web support as Google continues to push AVIF (it is debatable if it ever will be outside the Apple ecosystem). Even with AVIF, adoption isn\'t remotely close to JPEG, so it is worth providing a fallback. This can look like the following example:\\n\\n```html\\n<picture>\\n    <source srcset=\\"/img/jxl_image.jxl\\" type=\\"image/jxl\\" />\\n    <source srcset=\\"/img/avif_image.avif\\" type=\\"image/avif\\" />\\n    <source srcset=\\"/img/webp_fback.webp\\" type=\\"image/webp\\" />\\n    <img src=\\"/images/jpeg_fallback.jpg\\" alt=\\"alt text\\" width=\\"XX\\" height=\\"YY\\" loading=\\"lazy\\" />\\n</picture> \\n```\\n\\nHere is a JXL falling back to an AVIF falling back to a WebP falling back to a JPEG. Pretty intense to have this many fallbacks unless you\'re really after the ultimate compression ratio, but it is certainly an option. AVIF & JPEG alone will probably be enough for most.\\n\\n### Compression Efficacy\\n\\nLet\'s look at how our image examples compare to the original with our new codec selection. We\'ll be aiming for high visual fidelity, so around the same quality as our initial JPEG encoded with `cjpegli` (which scores ~`83.01` with the [SSIMULACRA2](/docs/metrics/SSIMULACRA2) visual fidelity metric).\\n\\n![smaller_jxl](/img/_DSC8466-smaller.jxl)\\n\\n**137.0 kB** *JPEG-XL image, encoded with `cjxl lossless.png out.jxl -d 1.49 -e 9`. Score: ~`83.04`* *3.06s user time*\\n\\n![smaller_avif](/img/_DSC8466-smaller.avif)\\n\\n**124.8 kB** *AVIF image, encoded with `avifenc -c aom -s 4 -j 8 -d 10 -y 444 --min 1 --max 63 -a end-usage=q -a cq-level=16 -a tune=ssim lossless.png out.avif`. Score: ~`83.03`* *7.54s user time*\\n\\nJXL also supports lossless transcoding of JPEG images. This means every pixel is identical, the image just has a smaller filesize than the original JPEG; if you can use JXL, you can transcode existing JPEGs losslessly on your site & save some bandwidth that way. The JPEG transcode below gives a higher SSIMULACRA2 score than the original for some reason, but I\'ll chalk that up to a decoding inconsistency between how the `ssimulacra2` program decodes JPEG & JXL. Either way, the scores are fairly close.\\n\\n![smaller_jxl_jpeg-recomp](/img/_DSC8466-smaller-recomp.jxl)\\n\\n**189.4 kB** *JPEG-XL image from JPEG, encoded with `cjxl input.jpg input-recomp.jxl -d 0.0 -e 9 --brotli_effort=11`. Score: ~`84.92` (???)* *0.67s user time*\\n\\nThe final trick we can use, while not a new codec at all, still increases quality per bit. Encoding an XYB JPEG with `cjpegli` encodes with the perceptual XYB colorspace using an ICC profile to modify the original JPEG colors, avoiding JPEG\'s normal YCbCr which isn\'t perceptually optimized for the human visual system. Using XYB, we can afford identical quality with less bitrate than normal JPEG. This has universal compatibility, but not every application understands how to handle the XYB color profile (although color-managed modern browsers should be fine).\\n\\n![smaller_jpeg_xyb](/img/_DSC8466-smaller-xyb.jpg)\\n\\n**208.3 kB** *XYB JPEG, encoded with `cjpegli lossless.png out.jpg --xyb -d 1.155`. Score: ~`83.04`* *0.10s user time*\\n\\nIn this particular instance, AVIF seems to be the overall winner. This isn\'t always the case due to JXL\'s superiority at higher fidelity & with more detailed images, but according to SSIMULACRA2, AVIF has the best quality per bit with this image. You can use your own eyes to further clarify your choice, though. It is worth mentioning that as these were encoded from a 16-bit source PNG, the JXL image is the only one that maintains the full original bit depth, & AVIF isn\'t fast to encode.\\n\\n## Responsive Images\\n\\nDisplaying an image that is too large for a viewport is a waste of bandwidth, & displaying an image that\'s too small for the viewport leaves fidelity to be desired. Luckily, we have the [Responsive Image Linter](https://ausi.github.io/respimagelint/) that can help us figure out which image sizes we should be using.\\n\\n![responsive_image_linter](/img/responsive_image_linter.avif)\\n\\nIn our fire & forget example, we see that we are serving an image that is far too large. We already know that, but now we can see that given various viewport sizes we could be serving images that have respective widths of 270px, 958px, 1350px, 1660px, & 1916px to optimize for delivery to a variety of different devices. Here\'s how we\'d write that in HTML:\\n\\n```html\\n<picture>\\n\u2003\u2003<source type=\\"image/jxl\\" srcset=\\"/img_270.jxl 270w, /img_958.jxl 958w, /img_1350.jxl 1350w, /img_1660.jxl 1660w, /img_1916.jxl 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" />\\n\u2003\u2003<source type=\\"image/avif\\" srcset=\\"/img_270.avif 270w, /img_958.avif 958w, /img_1350.avif 1350w, /img_1660.avif 1660w, /img_1916.avif 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" />\\n\u2003\u2003<img width=\\"1699\\" height=\\"1136\\" alt=\\"alt text\\" srcset=\\"/img_270.jpg 270w, /img_958.jpg 958w, /img_1350.jpg 1350w, /img_1660.jpg 1660w, /img_1916.jpg 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" src=\\"/fallback.jpg\\" />\\n</picture>\\n```\\n\\nIt is worth noting that this example above & the example below aren\'t perfect implementations of a responsive image given the conditions of this site, but the general concept still applies. Some things to note:\\n\\n- `srcset` = the images available to your browser to serve, & their respective widths\\n- `sizes` = the conditions given to the browser explaining under what conditions should it serve which image\\n- `(min-width: XXXpx) YYYpx` = Given the viewport is at least XXX wide, serve an image of YYY horizontal resolution. The browser will pick an image from srcset that is CSS pixels \\\\* display scaling.\\n- `calc(100vw - 24px)` = Usually preceded by a (min-width) condition. Specifies a value the browser should calculate on its own to pick the closest option from the srcset. Let\'s say we have `(min-width: 997px) calc(75vw - 257px)`. This means given the viewport is at least 997px wide, calculate 0.75 \\\\* the current viewport resolution - 257 to find the closest image in the srcset to fit the number of pixel specified.\\n\\n<picture>\\n\u2003\u2003<source type=\\"image/jxl\\" srcset=\\"https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_270.jxl 270w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_958.jxl 958w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1350.jxl 1350w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1660.jxl 1660w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1916.jxl 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" />\\n\u2003\u2003<source type=\\"image/avif\\" srcset=\\"https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_270.avif 270w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_958.avif 958w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1350.avif 1350w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1660.avif 1660w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1916.avif 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" />\\n\u2003\u2003<img loading=\\"lazy\\" width=\\"1699\\" height=\\"1136\\" alt=\\"alt text\\" srcset=\\"https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_270.jpg 270w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_958.jpg 958w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1350.jpg 1350w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1660.jpg 1660w, https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/img_size/img_1916.jpg 1916w\\" sizes=\\"(min-width: 2000px) 1916px, (min-width: 1700px) 1660px, (min-width: 1400px) 1350px, (min-width: 1000px) 958px, calc(100vw - 24px)\\" src=\\"https://raw.githubusercontent.com/av1-community-contributors/codec-wiki/deployment/img/_DSC8466-smaller.jpg\\" />\\n</picture>\\n\\nThat\'s all! Massive thanks to Auto-Rez Media Technologies for the inspiration behind this article & explicit permission to use their [Reduce Your Page\'s Image Load](https://autocompressor.net/blog/reduce-image-load) blog post when writing this entry. I have [confirmed](https://autumn.revolt.chat/attachments/GtFGuwNfeRdcwUN0MWzhDCAiiadWOk88XXC3pQv6RI) with their leadership that this wiki entry can be safely licensed under CC BY-SA 4.0."}]}')}}]);