"use strict";(self.webpackChunkcodec_wiki=self.webpackChunkcodec_wiki||[]).push([[4822],{7633:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>s,metadata:()=>r,toc:()=>d});var o=i(4848),n=i(8453);const s={label:"zpaq",sidebar_position:7},a="ZPAQ",r={id:"data/zpaq",title:"ZPAQ",description:"This section is in need of contributions. If you believe you can help, please see our Contribution Guide to get started as a contributor!",source:"@site/docs/data/zpaq.mdx",sourceDirName:"data",slug:"/data/zpaq",permalink:"/docs/data/zpaq",draft:!1,unlisted:!1,editUrl:"https://github.com/av1-community-contributors/codec-wiki/tree/main/docs/data/zpaq.mdx",tags:[],version:"current",sidebarPosition:7,frontMatter:{label:"zpaq",sidebar_position:7},sidebar:"tutorialSidebar",previous:{title:"Brotli",permalink:"/docs/data/brotli"},next:{title:"Zstandard",permalink:"/docs/data/zstd"}},c={},d=[];function l(e){const t={a:"a",admonition:"admonition",h1:"h1",p:"p",...(0,n.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"zpaq",children:"ZPAQ"}),"\n",(0,o.jsx)(t.admonition,{title:"Help Wanted",type:"danger",children:(0,o.jsxs)(t.p,{children:["This section is in need of contributions. If you believe you can help, please see our ",(0,o.jsx)(t.a,{href:"/docs/contribution-guide",children:"Contribution Guide"})," to get started as a contributor!"]})}),"\n",(0,o.jsx)(t.p,{children:"ZPAQ is a lossless data compression algorithm that combines several techniques to achieve high compression ratios. It was developed by Matt Mahoney."}),"\n",(0,o.jsx)(t.p,{children:'ZPAQ uses a multitude of different compression algorithms to try to achieve the best size-to-compression-time ratio possible while producing the smallest possible archives without much concern given to decompression performance. On the official ZPAQ website, it looks like it is designed for "realistic backups that have a lot of duplicate files and a lot of already compressed files."'}),"\n",(0,o.jsx)(t.p,{children:'ZPAQ is also considered an "incremental journaling archiver" meaning you can add files to an existing archive based on if they were changed or not. This reduces the time needed to wait for a new backup to finish, if that is your use case. Since ZPAQ is so focused on compression ratio, this kind of feature may reduce the burden imposed by long compression times in practical use cases where it makes sense. Windows & macOS do not handle ZPAQ archives properly by default, and it is unlikely many Linux distros do either.'})]})}function u(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,t,i)=>{i.d(t,{R:()=>a,x:()=>r});var o=i(6540);const n={},s=o.createContext(n);function a(e){const t=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:a(e.components),o.createElement(s.Provider,{value:t},e.children)}}}]);