"use strict";(self.webpackChunkcodec_wiki=self.webpackChunkcodec_wiki||[]).push([[5993],{7490:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>d,contentTitle:()=>l,default:()=>p,frontMatter:()=>a,metadata:()=>c,toc:()=>u});var t=n(4848),s=n(8453),o=n(1470),r=n(9365);const a={label:"SVT-AV1",sidebar_position:4},l="SVT-AV1",c={id:"encoders/SVT-AV1",title:"SVT-AV1",description:"The content in this entry is incomplete & is in the process of being completed.",source:"@site/docs/encoders/SVT-AV1.mdx",sourceDirName:"encoders",slug:"/encoders/SVT-AV1",permalink:"/docs/encoders/SVT-AV1",draft:!1,unlisted:!1,editUrl:"https://github.com/av1-community-contributors/codec-wiki/tree/main/docs/encoders/SVT-AV1.mdx",tags:[],version:"current",sidebarPosition:4,frontMatter:{label:"SVT-AV1",sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"vpxenc",permalink:"/docs/encoders/vpxenc"},next:{title:"rav1e",permalink:"/docs/encoders/rav1e"}},d={},u=[{value:"Community Forks",id:"community-forks",level:2},{value:"SVT-AV1-PSY",id:"svt-av1-psy",level:3},{value:"FFmpeg",id:"ffmpeg",level:2},{value:"Installation",id:"installation",level:2},{value:"Encoding",id:"encoding",level:2},{value:"Strengths",id:"strengths",level:3},{value:"Weaknesses",id:"weaknesses",level:3},{value:"Encoder Optimization",id:"encoder-optimization",level:3}];function h(e){const i={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.h1,{id:"svt-av1",children:"SVT-AV1"}),"\n",(0,t.jsx)(i.admonition,{title:"Under Maintenance",type:"info",children:(0,t.jsx)(i.p,{children:"The content in this entry is incomplete & is in the process of being completed."})}),"\n",(0,t.jsx)(i.p,{children:"SVT-AV1 (Scalable Video Technology for AV1) is an AV1-compliant software encoder/decoder library. Jointly developed by Intel and Netflix, SVT-AV1 is written almost entirely in C with some parts written in C++ and Assembly."}),"\n",(0,t.jsxs)(i.p,{children:['This entry discusses the SVT-AV1 encoder, also known as the "Production" AV1 encoder (while ',(0,t.jsx)(i.a,{href:"/docs/encoders/aomenc",children:"aomenc"}),' is the "reference" AV1 encoder), & refers to SVT-AV1 as such. SVT-AV1 is known for its parallelization, high coding efficiency, & active development. SVT-AV1 scales across multiple CPU cores much more effectively than aomenc or ',(0,t.jsx)(i.a,{href:"/docs/encoders/rav1e",children:"rav1e"}),", so the use of tools like ",(0,t.jsx)(i.a,{href:"/docs/utilities/av1an",children:"Av1an"})," is less helpful albeit still helpful for scene detection."]}),"\n",(0,t.jsx)(i.h2,{id:"community-forks",children:"Community Forks"}),"\n",(0,t.jsx)(i.p,{children:"Currently, there is only one noteworthy community fork of SVT-AV1 called SVT-AV1-PSY."}),"\n",(0,t.jsx)(i.h3,{id:"svt-av1-psy",children:"SVT-AV1-PSY"}),"\n",(0,t.jsxs)(i.p,{children:["SVT-AV1-PSY is a community fork of SVT-AV1 that strives to improve the perceptual fidelity and quality of life provided by the encoder. The goal of this project is to create the best encoding implementation for perceptual quality with AV1, and it aims to surpass previous community forks of ",(0,t.jsx)(i.a,{href:"/docs/encoders/aomenc#choosing-forks",children:"aomenc"})," in speed and visual quality."]}),"\n",(0,t.jsxs)(i.p,{children:["SVT-AV1-PSY has a number of feature additions to the mainline SVT-AV1 encoder as well as modified defaults that aim to make it easier to produce a more perceptually optimal bistream. For a full list of the encoder's feature additions and modifications to defaults, see the ",(0,t.jsx)(i.a,{href:"https://github.com/gianni-rosato/svt-av1-psy/blob/master/README.md#feature-additions",children:"project's README"}),"."]}),"\n",(0,t.jsxs)(i.p,{children:["SVT-AV1-PSY is used by default in ",(0,t.jsx)(i.a,{href:"/docs/utilities/Aviator",children:"Aviator"})," and can be used in ",(0,t.jsx)(i.a,{href:"/docs/utilities/rav1ator-cli",children:"rAV1ator CLI"})," by using the pre-compiled binaries available with the tool or by building a binary yourself."]}),"\n",(0,t.jsx)(i.p,{children:"SVT-AV1-PSY is a superset of SVT-AV1, meaning any valid SVT-AV1 command will work with SVT-AV1-PSY given the modified defaults do not conflict with the settings provided."}),"\n",(0,t.jsx)(i.h2,{id:"ffmpeg",children:"FFmpeg"}),"\n",(0,t.jsxs)(i.p,{children:["SVT-AV1 is available in FFmpeg via ",(0,t.jsx)(i.code,{children:"libsvtav1"}),", to check if you have it, run ",(0,t.jsx)(i.code,{children:"ffmpeg -h encoder=libsvtav1"}),". You can input non-FFmpeg standard SVT-AV1 parameters via ",(0,t.jsx)(i.code,{children:"-svtav1-params"}),"."]}),"\n",(0,t.jsx)(i.h2,{id:"installation",children:"Installation"}),"\n",(0,t.jsxs)(o.A,{children:[(0,t.jsxs)(r.A,{value:"unixlike",label:"Linux & macOS",children:[(0,t.jsx)(i.p,{children:(0,t.jsxs)(i.em,{children:["A precompiled AVX2-optimized binary of SVT-AV1-PSY can be installed for x86_64 Linux via ",(0,t.jsx)(i.a,{href:"/docs/utilities/rav1ator-cli",children:"rAV1ator CLI"}),". However, it is always recommended to build from source."]})}),(0,t.jsx)(i.p,{children:"To build SVT-AV1 from source, first clone the desired SVT-AV1 repository & enter the build directory."}),(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-bash",metastring:'title="Clone mainline SVT-AV1"',children:"git clone https://gitlab.com/AOMediaCodec/SVT-AV1/\ngit reset --hard 59645eea34e2815b627b8293aa3af254eddd0d69 # Reset to release 1.8.0\ncd SVT-AV1/Build/linux\n"})}),(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-bash",metastring:'title="Clone SVT-AV1-PSY"',children:"git clone https://github.com/gianni-rosato/svt-av1-psy\ncd SVT-AV1/Build/linux\n"})}),(0,t.jsxs)(i.p,{children:["In the directory, simply run ",(0,t.jsx)(i.code,{children:"./build.sh [flags]"})," to build. Be aware that building requires cmake version 3.16 or higher and either gcc or clang. It is recommended to use clang when building SVT-AV1."]}),(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-bash",metastring:'title="Build release"',children:"./build.sh release\n"})}),(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-bash",metastring:'title="Statically build just the encoder with clang and enable link-time optimization"',children:"./build.sh jobs=8 all cc=clang cxx=clang++ no-dec enable-lto static native\n"})}),(0,t.jsxs)(i.p,{children:["The compiled binaries will be in the Bin/Release directory, including SvtAv1EncApp. If you just want the encoder, adding the ",(0,t.jsx)(i.code,{children:"no-dec"})," flag will skip building SvtAv1DecApp and save on compilation time."]}),(0,t.jsxs)(i.p,{children:["If you'd like to build from the latest release (1.8.0 at the time of writing - last updated 11 Feb 2024) please run ",(0,t.jsx)(i.code,{children:"git reset --hard 59645eea34e2815b627b8293aa3af254eddd0d69"})," in the cloned directory. It is recommended that you do this, as new changes to git aren't always stable right away & a release will guarantee more stability."]}),(0,t.jsxs)(i.p,{children:["If you want extra performance, it is possible to build SVT-AV1 using PGO (Profile-guided Optimization). ",(0,t.jsxs)(i.strong,{children:["Be aware that this particular script infers that you have a .y4m file (or multiple) in ",(0,t.jsx)(i.code,{children:"/dev/shm"})," for transcoding"]}),". You can compile statically linked SVT-AV1 with PGO (and LTO, or link-time optimization) by following this script:"]}),(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-bash",metastring:'title="Bulding SVT-AV1 with profile guided optimization"',children:"git clone https://gitlab.com/AOMediaCodec/SVT-AV1/\ncd SVT-AV1/Build/linux\n./build.sh cc=gcc cxx=g++ enable-lto enable-pgo static native jobs=$(nproc) pgo-dir=/dev/shm pgo-videos=/dev/shm release\n"})}),(0,t.jsx)(i.p,{children:"If you wish to store videos elsewhere or provide custom parameters to the SvtAv1EncApp binary, try this script:"}),(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-bash",children:"git clone https://gitlab.com/AOMediaCodec/SVT-AV1/\ncd SVT-AV1/Build/linux\n./build.sh cc=gcc cxx=g++ enable-lto enable-pgo static native jobs=$(nproc) pgo-dir=/dev/shm pgo-compile-gen release\n../../Bin/Release/SvtAv1EncApp # Run this binary as many times as you'd like with arguments of your choice to collect data\n./build.sh cc=gcc cxx=g++ enable-lto enable-pgo static native jobs=$(nproc) pgo-dir=/dev/shm pgo-compile-use release\n"})})]}),(0,t.jsx)(r.A,{value:"windows",label:"Windows",children:(0,t.jsxs)(i.p,{children:["To be filled. If you believe you can help, see our ",(0,t.jsx)(i.a,{href:"/docs/contribution-guide",children:"Contribution Guide"}),"."]})})]}),"\n",(0,t.jsx)(i.h2,{id:"encoding",children:"Encoding"}),"\n",(0,t.jsx)(i.h3,{id:"strengths",children:"Strengths"}),"\n",(0,t.jsx)(i.p,{children:"SVT-AV1's greatest strength is its parallelization capability, where it outclasses other AV1 encoders by a significant margin. SVT-AV1's parallelization techniques do not involve tiling & don't harm video quality, & can comfortably utilize up to 16 cores given 1080p source video. This is while maintaining competitive coding efficiency to mainline aomenc. Perceptually, mainline SVT-AV1 is outperformed by well-tuned community forks of aomenc, but according to many the gap has begun to close with the introduction of SVT-AV1-PSY."}),"\n",(0,t.jsx)(i.h3,{id:"weaknesses",children:"Weaknesses"}),"\n",(0,t.jsxs)(i.p,{children:["SVT-AV1 is strongest on x86 CPUs, & while ARM NEON assembly is ",(0,t.jsx)(i.a,{href:"https://gitlab.com/AOMediaCodec/SVT-AV1/-/commit/ba13fac241f1b54954935f2cb200efc07f3de13a",children:"available"})," and has been slowly improving since its introduction in version 1.8.0, SVT-AV1 still underperforms on ARM. For this reason, it is not a good cross-architecture CPU benchmark. SVT-AV1's support for various AV1 features is also limited; it only supports up to 4:2:0 chroma subsampling with no support for 12-bit color, and it does not support scene change detection (there are no plans to implement this, either). The smallest possible video that SVT-AV1 can produce is 64x64."]}),"\n",(0,t.jsx)(i.h3,{id:"encoder-optimization",children:"Encoder Optimization"}),"\n",(0,t.jsxs)(i.p,{children:["Aside from build optimizations for speed, there is further tweaking to be done to the ",(0,t.jsx)(i.code,{children:"SvtAv1EncApp"})," binary parameters when encoding. The following applies to mainline SVT-AV1, but does not apply to SVT-AV1-PSY."]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"--film-grain"})," & ",(0,t.jsx)(i.code,{children:"--film-grain-denoise"})]}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:["Most live-action sources feature hard-to-compress digital noise that is easily smoothed out by AV1 compression. To add this grain back, or even denoise through the encoder and then add grain, it is possible to use the ",(0,t.jsx)(i.code,{children:"--film-grain"})," parameter to specify an amount of film grain to add to the encode (& ",(0,t.jsx)(i.code,{children:"--film-grain-denoise"})," to specify how to denoise the input video before encoding for potentially better appeal). Denoising a video always removes fine details, so sticking with just ",(0,t.jsx)(i.code,{children:"--film-grain"})," is recommended in most cases. According to ",(0,t.jsx)(i.a,{href:"https://gitlab.com/AOMediaCodec/SVT-AV1/-/blob/master/Docs/CommonQuestions.mdx#practical-advice-on-grain-synthesis",children:"SVT-AV1 documentation"}),", a level of 8 should be used for live-action content with a normal amount of grain while a level of 4 works well for hand-drawn animation or other smoother-looking sources that still stand to benefit from some grain synthesis."]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"--input-depth 10"})}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"10-bit output from AV1 encoding is always desirable for coding efficiency, even if your source is 8-bit. This option only produces a 10-bit AV1 bitstream if the source provided to the encoder is 10-bit."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"--tune 2"})}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:["There are three tunes in mainline SVT-AV1: Tune 1 is for ",(0,t.jsx)(i.a,{href:"/docs/metrics/PSNR",children:"PSNR"})," ",(0,t.jsx)(i.a,{href:"/docs/introduction/psychovisual",children:"RDO"}),", Tune 2 is for ",(0,t.jsx)(i.a,{href:"/docs/metrics/SSIM",children:"SSIM"})," RDO, & Tune 0 is a ",(0,t.jsx)(i.a,{href:"/docs/introduction/psychovisual",children:"psychovisual"})," tune labeled VQ. It has been common practice to lean away from the PSNR tune, as it is not designed for visual quality but rather to perform better on the PSNR metric which is widely considered to be inconsistent with our human perception of fidelity. Using the VQ tune is a safe bet for now, but many believe the newer SSIM tune provides better visual fidelity."]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"--enable-qm 1"})}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Enables quantization matrices, disabled by default. Improves coding efficiency mainly by improving encoding speed while producing similar quality video."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"--qm-min 0"})}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Sets the minimum flatness of quantization matrices to 0, down from the default 8. This is recommended. The maximum quantization matrix flatness is 15 by default, and should be left alone"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"--keyint [FPS*10]"})}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:["Similar to ",(0,t.jsx)(i.code,{children:"--kf-max-dist"})," in ",(0,t.jsx)(i.a,{href:"/docs/encoders/vpxenc",children:"vpxenc"}),", this tells the encoder when to place keyframes. Because SVT-AV1 doesn't have scene detection, this isn't the maximum distance between keyframes, but rather a fixed interval for placing keyframes. If using Av1an, set to -1 to disable keyframe insertion as Av1an handles that instead."]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"--irefresh-type 2"})}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:["Intra refresh is specified through this option, & lets the user decide between Closed GOP & Open GOP. GOP stands for Group of Pictures. Open GOP allows GOPs to ",(0,t.jsx)(i.a,{href:"https://ottverse.com/closed-gop-open-gop-idr/",children:"reference one another"}),", but support for this feature is currently incomplete. Therefore, it is recommended to use Closed GOP for the time being via ",(0,t.jsx)(i.code,{children:"--irefresh-type 2"})," until this is rectified."]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"--preset X"})}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"SVT-AV1 can be used in 14 different presets, labeled -1 through 13. Preset -1 is the slowest, but provides the best coding efficiency; it is also dubbed a research preset that is not recommended for regular use. Preset 13 is the fastest, and is also not recommended for regular use as it makes serious trade-offs to achieve unrealistically fast speeds at the cost of the encoder's coding efficiency. Using presets 2 through 8 is the best course of action for non-realtime applications if you desire reasonable speed, while 9 through 12 are useful for real-time encoding at 1080p or lower, even on low-end consumer computer hardware."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.code,{children:"--crf X"})}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"CRF is the best way to target quality for optimal visual fidelity. VBR & CBR lose efficiency due to their inherently limited rate control capabilities."})]})}function p(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},9365:(e,i,n)=>{n.d(i,{A:()=>r});n(6540);var t=n(8215);const s={tabItem:"tabItem_Ymn6"};var o=n(4848);function r(e){let{children:i,hidden:n,className:r}=e;return(0,o.jsx)("div",{role:"tabpanel",className:(0,t.A)(s.tabItem,r),hidden:n,children:i})}},1470:(e,i,n)=>{n.d(i,{A:()=>j});var t=n(6540),s=n(8215),o=n(3104),r=n(6347),a=n(205),l=n(7485),c=n(1682),d=n(9466);function u(e){return t.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:i}=e;return!!i&&"object"==typeof i&&"value"in i}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function h(e){const{values:i,children:n}=e;return(0,t.useMemo)((()=>{const e=i??function(e){return u(e).map((e=>{let{props:{value:i,label:n,attributes:t,default:s}}=e;return{value:i,label:n,attributes:t,default:s}}))}(n);return function(e){const i=(0,c.X)(e,((e,i)=>e.value===i.value));if(i.length>0)throw new Error(`Docusaurus error: Duplicate values "${i.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[i,n])}function p(e){let{value:i,tabValues:n}=e;return n.some((e=>e.value===i))}function m(e){let{queryString:i=!1,groupId:n}=e;const s=(0,r.W6)(),o=function(e){let{queryString:i=!1,groupId:n}=e;if("string"==typeof i)return i;if(!1===i)return null;if(!0===i&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:i,groupId:n});return[(0,l.aZ)(o),(0,t.useCallback)((e=>{if(!o)return;const i=new URLSearchParams(s.location.search);i.set(o,e),s.replace({...s.location,search:i.toString()})}),[o,s])]}function f(e){const{defaultValue:i,queryString:n=!1,groupId:s}=e,o=h(e),[r,l]=(0,t.useState)((()=>function(e){let{defaultValue:i,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(i){if(!p({value:i,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${i}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return i}const t=n.find((e=>e.default))??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:i,tabValues:o}))),[c,u]=m({queryString:n,groupId:s}),[f,b]=function(e){let{groupId:i}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(i),[s,o]=(0,d.Dv)(n);return[s,(0,t.useCallback)((e=>{n&&o.set(e)}),[n,o])]}({groupId:s}),g=(()=>{const e=c??f;return p({value:e,tabValues:o})?e:null})();(0,a.A)((()=>{g&&l(g)}),[g]);return{selectedValue:r,selectValue:(0,t.useCallback)((e=>{if(!p({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),b(e)}),[u,b,o]),tabValues:o}}var b=n(2303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var v=n(4848);function x(e){let{className:i,block:n,selectedValue:t,selectValue:r,tabValues:a}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,o.a_)(),d=e=>{const i=e.currentTarget,n=l.indexOf(i),s=a[n].value;s!==t&&(c(i),r(s))},u=e=>{let i=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const n=l.indexOf(e.currentTarget)+1;i=l[n]??l[0];break}case"ArrowLeft":{const n=l.indexOf(e.currentTarget)-1;i=l[n]??l[l.length-1];break}}i?.focus()};return(0,v.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},i),children:a.map((e=>{let{value:i,label:n,attributes:o}=e;return(0,v.jsx)("li",{role:"tab",tabIndex:t===i?0:-1,"aria-selected":t===i,ref:e=>l.push(e),onKeyDown:u,onClick:d,...o,className:(0,s.A)("tabs__item",g.tabItem,o?.className,{"tabs__item--active":t===i}),children:n??i},i)}))})}function V(e){let{lazy:i,children:n,selectedValue:s}=e;const o=(Array.isArray(n)?n:[n]).filter(Boolean);if(i){const e=o.find((e=>e.props.value===s));return e?(0,t.cloneElement)(e,{className:"margin-top--md"}):null}return(0,v.jsx)("div",{className:"margin-top--md",children:o.map(((e,i)=>(0,t.cloneElement)(e,{key:i,hidden:e.props.value!==s})))})}function y(e){const i=f(e);return(0,v.jsxs)("div",{className:(0,s.A)("tabs-container",g.tabList),children:[(0,v.jsx)(x,{...e,...i}),(0,v.jsx)(V,{...e,...i})]})}function j(e){const i=(0,b.A)();return(0,v.jsx)(y,{...e,children:u(e.children)},String(i))}},8453:(e,i,n)=>{n.d(i,{R:()=>r,x:()=>a});var t=n(6540);const s={},o=t.createContext(s);function r(e){const i=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(o.Provider,{value:i},e.children)}}}]);