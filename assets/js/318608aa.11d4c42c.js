"use strict";(self.webpackChunkcodec_wiki=self.webpackChunkcodec_wiki||[]).push([[3248],{1440:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var t=i(5893),s=i(1151);const o={title:"vpxenc",sidebar_position:3},r="vpxenc",l={id:"encoders/vpxenc",title:"vpxenc",description:"The content in this entry is incomplete & is in the process of being completed.",source:"@site/docs/encoders/vpxenc.mdx",sourceDirName:"encoders",slug:"/encoders/vpxenc",permalink:"/docs/encoders/vpxenc",draft:!1,unlisted:!1,editUrl:"https://github.com/av1-community-contributors/codec-wiki/tree/main/docs/encoders/vpxenc.mdx",tags:[],version:"current",sidebarPosition:3,frontMatter:{title:"vpxenc",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"aomenc",permalink:"/docs/encoders/aomenc"},next:{title:"SVT-AV1",permalink:"/docs/encoders/SVT-AV1"}},a={},c=[{value:"Building",id:"building",level:2},{value:"VP8",id:"vp8",level:2},{value:"VP9",id:"vp9",level:2},{value:"Encoding",id:"encoding",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"vpxenc",children:"vpxenc"}),"\n",(0,t.jsx)(n.admonition,{title:"Under Maintenance",type:"info",children:(0,t.jsx)(n.p,{children:"The content in this entry is incomplete & is in the process of being completed."})}),"\n",(0,t.jsxs)(n.p,{children:["vpxenc is part of the libvpx library for working with the ",(0,t.jsx)(n.a,{href:"/docs/video/VP9",children:"VP9"})," & ",(0,t.jsx)(n.a,{href:"/docs/video/VP8",children:"VP8"})," video codecs. It is capable of encoding & decoding both formats, where vpxenc is the multipurpose encoder. VP9 competes with ",(0,t.jsx)(n.a,{href:"/docs/video/HEVC",children:"HEVC"})," (h265) & ",(0,t.jsx)(n.a,{href:"/docs/video/AVC",children:"AVC"})," (h264) in coding efficiency, and has been superseded by ",(0,t.jsx)(n.a,{href:"/docs/video/AV1",children:"AV1"}),". VP8 competes with AVC. By default, vpxenc isn't as competitive as it could be, but even when used properly, most tests show that h265 offers slightly better quality per bit with efficient encoders like ",(0,t.jsx)(n.a,{href:"/docs/encoders/x265",children:"x265"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"building",children:"Building"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Linux & macOS"})}),"\n",(0,t.jsx)(n.p,{children:"To build libvpx from source:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"git clone https://chromium.googlesource.com/webm/libvpx\ncd libvpx\n./configure\nmake -j [# of CPU threads]\n"})}),"\n",(0,t.jsxs)(n.p,{children:["It may be worth digging through the ",(0,t.jsx)(n.code,{children:"configure"})," options, which can be listed by running ",(0,t.jsx)(n.code,{children:"./configure -h"}),". Keeping in mind some flags might be redundant with defaults, here's an example of a tweaked configuration (without VP8 support) for efficient performance on an Apple Silicon Mac running macOS Ventura:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'./configure --disable-vp8 --target=arm64-darwin22-gcc --disable-docs --enable-webm-io --enable-vp9-postproc --enable-vp9-highbitdepth --extra-cxxflags="-O3 -flto -march=native" --extra-cflags="-O3 -flto -march=native" --enable-postproc\n'})}),"\n",(0,t.jsxs)(n.p,{children:["From the build, a binary will be produced called ",(0,t.jsx)(n.code,{children:"vpxenc"}),". You can copy this build to ",(0,t.jsx)(n.code,{children:"/usr/local/bin"})," or execute it directly in the directory, shown below:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"./vpxenc --help | grep vp9 -C 3\n\nIncluded encoders:\n\n    vp9    - WebM Project VP9 Encoder v1.13.0 (default)\n\n        Use --codec to switch to a non-default encoder.\n"})}),"\n",(0,t.jsx)(n.h2,{id:"vp8",children:"VP8"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Incomplete"})}),"\n",(0,t.jsx)(n.h2,{id:"vp9",children:"VP9"}),"\n",(0,t.jsxs)(n.p,{children:["For encoding VP9, vpxenc's default parameters are not considered optimal. There are a lot of options that are either disabled without reason or are simply misconfigured, hurting coding efficiency at little cost otherwise. As of mid-2021, some parameters (the TPL-model, lag-in-frames and auto-alt-ref frames) were changed (since libvpx 1.9.0 and libvpx 1.10.0) which means that there's not much use of setting these three parameters unless you're in ",(0,t.jsx)(n.a,{href:"/docs/utilities/ffmpeg",children:"FFmpeg"}),". This section covers the most important options libvpx-vp9 has to offer, recommended settings, & what they do."]}),"\n",(0,t.jsx)(n.h3,{id:"encoding",children:"Encoding"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--codec=vp9"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Self-explanatory."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--passes=2"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["vpxenc's 2-pass mode is quite fast compared to 2-pass in ",(0,t.jsx)(n.a,{href:"/docs/encoders/x264",children:"x264"})," and x265. Only use 1-pass mode for real-time applications, which won't be covered here yet. It is the default in the standalone vpxenc libvpx-vp9 encoder."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--webm"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Enables WebM output for the encoder, and passes the encoder flags set. It is not necessary to enable it, but since it passes the encoder flags, I would use it. Can be changed to ",(0,t.jsx)(n.code,{children:"--ivf"})," for an ivf video stream."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--good"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This is a sort of quality deadline, the minimum speed the encoder is allowed to go to. It isn't recommended to use ",(0,t.jsx)(n.code,{children:"-\u2013best"})," as it is slow for the quality uplift you get. Do not use RT for anything but real-time encoding."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--threads=8"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Dictates the number of threads the encoder should spawn. It doesn\u2019t mean it\u2019ll scale all that well over those 8 threads. On a 16 thread CPU with a single encoder instance, I would use 8 threads. With multiple encoder instance encoding(with qencoder/av1an/neav1e), I would set it to 2 threads."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--profile=2"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"VP9 profile 2 is obligatory if you want 10-bit & 12-bit support for HDR, and improved quality from 8-bit."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--lag-in-frames=25"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Lag-in-frames is the libvpx equivalent of lookahead in x264. The higher the number, the slower the encoder will be, but at the upside of making it more efficient. Going above \u2013lag-in-frames=12 also activates another setting called alternate reference frames. 25 is the maximum you can get in libvpx-vp9. It is the default in the standalone vpxenc libvpx-vp9 encoder."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--end-usage=q"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Q mode is the closest equivalent to CRF that libvpx-vp9 offers, so use it if maximum quality is desired."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--cq-level=25"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"For 1080p30 8-bit content, it is recommended to go with a Q of 25; you can go lower if you value higher quality over pure efficiency. For 1080p60 8-bit content, I would recommend going with a higher Q value with a delta of around 15. So, a Q of 30 to 40 is usually recommended. Depending on the content, you may have to tune this value, so this advice is only useful in choosing a starting point."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--kf-max-dist=[input FPS * 10]"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This tells the encoder to have a maximum number of frames between keyframes. It will usually place a lower number of keyframes in content like movies, TV shows, or animated shows, so you can set it to a very high number or not set it at all if you want maximum efficiency for this kind of content. Otherwise, I would go with the 10-second rule: ",(0,t.jsx)(n.code,{children:"--kf-max-dist=240"})," for 24FPS content, 300 for 30FPS content, 600 for 60FPS content, and so on."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--cpu-used=3"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This is where the biggest balance of quality to speed is with libvpx-vp9. This is similar to presets in x264 and x265, except the lower the number, the slower the encoder takes. Using ",(0,t.jsx)(n.code,{children:"--cpu-used=3"})," & below enables RDO, which increases quality at the expense of speed. Another note: --cpu-used=5 and above are ",(0,t.jsx)(n.em,{children:"slower"})," in the 1st pass, so it isn't recommended to use them anyway."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--auto-alt-ref=1"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:['Activates alternate reference frames. Alternate reference frames are "invisible" frames which are used as references when creating the final display frames. This allows the encoder to be a lot more efficient, so always use it. It is the default in the latest standalone vpxenc libvpx-vp9 encoder. ',(0,t.jsx)(n.code,{children:"--auto-alt-ref=6"})," can also be used, but be aware that this does require ",(0,t.jsx)(n.code,{children:"--profile=2"})," be set as mentioned above."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--arnr-maxframes=7"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"This is the maximum number of alternate reference frames the encoder is allowed to use. For most content, 7 is usually a good bet, and it is the default. With animated content, going with a value of 12 or to the max is a good bet, as animated content benefits from more additional alt-ref frames than other content. Be aware that increasing this value will impact encode speed."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--arnr-strength=4"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"This setting dictates how much denoising will occur in the alt-ref frames. Lowering it to 2 or 3 is usually a good bet for noisier/grainy content to try and retain more detail, but 4 is a sane starting place. The default setting is 5, which is fine for most content, but it can be beneficial going a bit lower. For animation, keeping the default of 5 is likely a better option."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--aq-mode=0"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Adaptive quantization is the way for an encoder to spend more bits in certain areas to improve ",(0,t.jsx)(n.a,{href:"/docs/introduction/psychovisual",children:"psychovisual fidelity"}),". ",(0,t.jsx)(n.code,{children:"-\u2013aq-mode=0"})," works well on clean content (animation, video games, screen content). ",(0,t.jsx)(n.code,{children:"--aq-mode=2"})," is recommended when you want to give more detail to more complex parts of a video."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--frame-boost=1"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This flag lets the encoder periodically boost the bitrate of a scene/frame if it needs it. Leaving it at the default ",(0,t.jsx)(n.code,{children:"--frame-boost=0"})," is usually a good bet, & this isn't a particularly salient change."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--tune-content=default"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This determines how the encoder is tuned. In libvpx-vp9, there are three options: ",(0,t.jsx)(n.code,{children:"default"}),", ",(0,t.jsx)(n.code,{children:"screen"}),", and ",(0,t.jsx)(n.code,{children:"film"}),". Default is for most scenarios, screen is for screen content(video games, live-streaming content like web pages & your screen), and film is for heavily dithered/grainy video. Leaving it at the default for about everything but screen content as described above is probably the best option. ",(0,t.jsx)(n.code,{children:"--tune-content=screen"})," with ",(0,t.jsx)(n.code,{children:"--aq-mode=2"})," is not recommended, as it creates some odd artifacts. It is advised to use ",(0,t.jsx)(n.code,{children:"--aq-mode=0"})," if ",(0,t.jsx)(n.code,{children:"--tune-content=screen"})," is activated, or if you want better perceptual quality, ",(0,t.jsx)(n.code,{children:"--aq-mode=1"}),"."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--row-mt=1"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Enables row multi-threading in libvpx-vp9. ",(0,t.jsx)(n.em,{children:"Always"})," enable it no matter what, as it does not hurt efficiency, but boosts speed considerably. This feature is disabled by default."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--bit-depth=10"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Always use 10-bit for maximum efficiency & minimal banding, even with an 8-bit source. Make sure to enable ",(0,t.jsx)(n.code,{children:"-\u2013profile=2"})," as mentioned above."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--tile-columns=1"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This setting divides the video into tile columns for easier parallelization when encoding & decoding. Setting ",(0,t.jsx)(n.code,{children:"-\u2013tile-columns=1"}),", you will get 2\xb9 tile columns. Setting it higher is a trade-off between parallelization & coding efficiency, as more tiles means less information your encoder can work with, and this will result in decreased efficiency. Do note there is an upper threshold in regards to the number of tile columns you can get due to the fixed minimum tile width of 256 pixels. So, this means 4 tile columns (2\xb2) for 720p and 1080p, 8 tile columns (2\u2074) for 1440p/4k, and so on. If you set a tile column number that is too high, it will drop down to the lowest supported number of tile columns at the input resolution."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--tile-rows=0"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This setting divides the video into tile rows. This option is different from columns because although it also makes decoding performance higher, it does not scale as well as tile columns & doesn\u2019t increase encoder threading nearly as much. Always use more tile-columns than rows, or leave the number of tile rows at default (0). Leaving the encoder defaults at ",(0,t.jsx)(n.code,{children:"-\u2013tile-rows=0"})," & ",(0,t.jsx)(n.code,{children:"\u2013-tile-columns=0"})," will result in the highest overall coding efficiency possible with these options."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"--enable-tpl=1"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"This option enables a temporal layer model, which helps with coding efficiency. It is the default in the standalone vpxenc libvpx-vp9 encoder."}),"\n",(0,t.jsx)(n.p,{children:"All of these options are only available for the standalone vpxenc program. Here is a sample FFmpeg command line interpretation of the commands above, with some options missing:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"ffmpeg -i input.mkv -c:v libvpx-vp9 -pix_fmt yuv420p10le -pass 1 -quality good -threads 4 -profile:v 2 -lag-in-frames 25 -crf 25 -b:v 0 -g 240 -cpu-used 4 -auto-alt-ref 1 -arnr-maxframes 7 -arnr-strength 4 -aq-mode 0 -tile-rows 0 -tile-columns 1 -enable-tpl 1 -row-mt 1 -f null -\nffmpeg -i input.mkv -c:v libvpx-vp9 -pix_fmt yuv420p10le -pass 2 -quality good -threads 4 -profile:v 2 -lag-in-frames 25 -crf 25 -b:v 0 -g 240 -cpu-used 4 -auto-alt-ref 1 -arnr-maxframes 7 -arnr-strength 4 -aq-mode 0 -tile-rows 0 -tile-columns 1 -enable-tpl 1 -row-mt 1 output.mkv\n"})}),"\n",(0,t.jsx)(n.p,{children:"Alternatively, you can pass a raw .y4m stream to standalone vpxenc & encode that way."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"VP9 section written based on work by BlueSwordM, who has granted written permission for this wiki page to exist in its current fashion"})})]})}function h(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},1151:(e,n,i)=>{i.d(n,{Z:()=>l,a:()=>r});var t=i(7294);const s={},o=t.createContext(s);function r(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);