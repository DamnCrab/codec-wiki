"use strict";(self.webpackChunkcodec_wiki=self.webpackChunkcodec_wiki||[]).push([[5885],{5190:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>l});var s=t(4848),n=t(8453);const r={title:"Stabilizing",sidebar_position:7},o="Stabilizing",a={id:"filtering/stabilizing",title:"Stabilizing",description:"This section is in need of contributions. If you believe you can help, please see our Contribution Guide to get started as a contributor!",source:"@site/docs/filtering/stabilizing.mdx",sourceDirName:"filtering",slug:"/filtering/stabilizing",permalink:"/docs/filtering/stabilizing",draft:!1,unlisted:!1,editUrl:"https://github.com/av1-community-contributors/codec-wiki/tree/main/docs/filtering/stabilizing.mdx",tags:[],version:"current",sidebarPosition:7,frontMatter:{title:"Stabilizing",sidebar_position:7},sidebar:"tutorialSidebar",previous:{title:"Decombing",permalink:"/docs/filtering/decombing"},next:{title:"Denoise",permalink:"/docs/filtering/denoise"}},d={},l=[{value:"Overview",id:"overview",level:2},{value:"Usage",id:"usage",level:2},{value:"vidstabdetect Parameters",id:"vidstabdetect-parameters",level:3},{value:"vidstabtransform Parameters",id:"vidstabtransform-parameters",level:3},{value:"Notes",id:"notes",level:2}];function c(e){const i={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,n.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.header,{children:(0,s.jsx)(i.h1,{id:"stabilizing",children:"Stabilizing"})}),"\n",(0,s.jsx)(i.admonition,{title:"Help Wanted",type:"danger",children:(0,s.jsxs)(i.p,{children:["This section is in need of contributions. If you believe you can help, please see our ",(0,s.jsx)(i.a,{href:"/docs/contribution-guide",children:"Contribution Guide"})," to get started as a contributor!"]})}),"\n",(0,s.jsx)(i.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsxs)(i.p,{children:["Stabilizing is a process that reduces unwanted camera movement and shakes in a video clip. This is particularly important, as unpredictable global movement (such as that from a handheld camera) can decrease overall encoding efficiency. The most popular way to stabilize video with ",(0,s.jsx)(i.a,{href:"/docs/utilities/ffmpeg",children:"FFmpeg"})," is to use the ",(0,s.jsx)(i.a,{href:"https://github.com/georgmartius/vid.stab",children:"VidStab"})," library. To do this, you need a build of FFmpeg compiled with ",(0,s.jsx)(i.code,{children:"--enable-libvidstab"}),"."]}),"\n",(0,s.jsx)(i.p,{children:"VidStab actually has two filters within FFmpeg."}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-shell",children:"ffmpeg -hide_banner -filters | grep vidstab\n ... vidstabdetect     V->V       Extract relative transformations, pass 1 of 2 for stabilization (see vidstabtransform for pass 2).\n ... vidstabtransform  V->V       Transform the frames, pass 2 of 2 for stabilization (see vidstabdetect for pass 1).\n"})}),"\n",(0,s.jsxs)(i.p,{children:["The ",(0,s.jsx)(i.code,{children:"vidstabdetect"})," filter is used for the first pass, where the video transformations file (",(0,s.jsx)(i.code,{children:".trf"}),") is generated, and ",(0,s.jsx)(i.code,{children:"vidstabtransform"})," is used for the second pass, where transformations are actually applied. This implies that stabilization cannot be achieved in real-time."]}),"\n",(0,s.jsx)(i.h2,{id:"usage",children:"Usage"}),"\n",(0,s.jsx)(i.p,{children:"To stabilize a video using default parameters, you need to run two FFmpeg commands:"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-shell",children:"ffmpeg -i input.mp4 -vf vidstabdetect -f null -\nffmpeg -i input.mp4 -vf vidstabtransform output.mp4\n"})}),"\n",(0,s.jsxs)(i.p,{children:["A file called ",(0,s.jsx)(i.code,{children:"transforms.trf"})," will be created in the directory where you run FFmpeg. After the second step is finished, you can safely remove it. The resulting ",(0,s.jsx)(i.code,{children:"output.mp4"})," video will now have reduced shakiness."]}),"\n",(0,s.jsxs)(i.p,{children:["To stabilize a high-framerate video with strong camera movement, set its transformations filename to ",(0,s.jsx)(i.code,{children:"a.trf"}),", and increase the output field of view. You can use the following commands:"]}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-shell",children:"ffmpeg -i input.mp4 -vf vidstabdetect=shakiness=8:result=a.trf -f null -\nffmpeg -i input.mp4 -vf vidstabtransform=smoothing=30:zoom=-5:input=a.trf output.mp4\n"})}),"\n",(0,s.jsx)(i.admonition,{type:"tip",children:(0,s.jsxs)(i.p,{children:["Remember to set appropriate video/audio codec parameters in the command before ",(0,s.jsx)(i.code,{children:"output.mp4"}),". You must not use ",(0,s.jsx)(i.code,{children:"-c:v copy"}),", as the video will be transformed."]})}),"\n",(0,s.jsx)(i.h3,{id:"vidstabdetect-parameters",children:"vidstabdetect Parameters"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"result"}),": Sets the output ",(0,s.jsx)(i.code,{children:".trf"})," file location"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"shakiness"}),": The amount of movement reduction, where ",(0,s.jsx)(i.code,{children:"1"})," is the least reduction, ",(0,s.jsx)(i.code,{children:"10"})," is the most reduction (highest stabilization), and ",(0,s.jsx)(i.code,{children:"5"})," is the default"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"accuracy"}),": The accuracy of movement reduction, where ",(0,s.jsx)(i.code,{children:"1"})," is the least accurate, ",(0,s.jsx)(i.code,{children:"15"})," is the most accurate, and ",(0,s.jsx)(i.code,{children:"15"})," is also the default. This setting influences CPU usage during detection. FFmpeg does not allow setting a value lower than ",(0,s.jsx)(i.code,{children:"3"}),". ",(0,s.jsx)(i.code,{children:"3"})," gave a processing speed of ",(0,s.jsx)(i.code,{children:"21 fps"}),", and ",(0,s.jsx)(i.code,{children:"15"})," gave ",(0,s.jsx)(i.code,{children:"14 fps"}),". The process itself is rather CPU-intensive."]}),"\n"]}),"\n",(0,s.jsxs)(i.p,{children:["For a description of all possible parameters, take a look ",(0,s.jsx)(i.a,{href:"https://ffmpeg.org/ffmpeg-filters.html#vidstabdetect-1",children:"here"}),"."]}),"\n",(0,s.jsx)(i.h3,{id:"vidstabtransform-parameters",children:"vidstabtransform Parameters"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"input"}),": Sets the input ",(0,s.jsx)(i.code,{children:".trf"})," file location created by ",(0,s.jsx)(i.code,{children:"vidstabdetect"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"smoothing"}),": The number of frames in the future and past used for movement estimation, where the default is ",(0,s.jsx)(i.code,{children:"10"})," (so 10 past and 10 future frames)"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"zoom"}),": The amount of zoom expressed in percentage, where the default is ",(0,s.jsx)(i.code,{children:"0%"}),". It can be negative, which will create a zoom-out effect."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"interpol"}),": The type of interpolation used, where ",(0,s.jsx)(i.code,{children:"bilinear"})," is the default.","\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"no"}),": No interpolation"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"linear"}),": Only horizontal"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"bilinear"}),": Faster but can result in blurry output"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"bicubic"}),": Slower"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.p,{children:["For a description of all possible parameters, take a look ",(0,s.jsx)(i.a,{href:"https://ffmpeg.org/ffmpeg-filters.html#vidstabtransform-1",children:"here"}),"."]}),"\n",(0,s.jsx)(i.h2,{id:"notes",children:"Notes"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"The process of stabilization is lossy and can reduce the quality of the video, mainly due to the zoom and interpolation used."}),"\n",(0,s.jsx)(i.li,{children:"You might notice overall wobbliness in the resulting video file, especially with higher stabilization levels. This is just how this filter works."}),"\n",(0,s.jsx)(i.li,{children:"As you will need to run two passes anyway, you might also consider using two-pass encoding, depending on your use case."}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,n.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,i,t)=>{t.d(i,{R:()=>o,x:()=>a});var s=t(6540);const n={},r=s.createContext(n);function o(e){const i=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:o(e.components),s.createElement(r.Provider,{value:i},e.children)}}}]);